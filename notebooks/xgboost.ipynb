{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from functools import partial\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import cv\n",
    "from optuna import create_study\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.distributions import IntDistribution, FloatDistribution\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna import Trial\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv('/workspaces/2025SE-Mike.N-HSC-AT2/data/concrete_preprocessed.csv')\n",
    "y = X_full['strength']\n",
    "X = X_full.drop(['strength'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 996 entries, 0 to 995\n",
      "Data columns (total 11 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   cement                           996 non-null    float64\n",
      " 1   blast_furnace_slag               996 non-null    float64\n",
      " 2   fly_ash                          996 non-null    float64\n",
      " 3   water                            996 non-null    float64\n",
      " 4   superplasticizer                 996 non-null    float64\n",
      " 5   coarse_aggregate                 996 non-null    float64\n",
      " 6   fine_aggregate                   996 non-null    float64\n",
      " 7   age                              996 non-null    float64\n",
      " 8   cement_to_water_ratio            996 non-null    float64\n",
      " 9   fine_aggregate_to_water_ratio    996 non-null    float64\n",
      " 10  coarse_aggregate_to_water_ratio  996 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 85.7 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 996 entries, 0 to 995\n",
      "Series name: strength\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "996 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training** \\\n",
    "We divide the training phase into 2 phases:\n",
    "* In the 1st phase, we use Optuna to find the best tree parameters with a medium learning rate to improve trial speeds.\n",
    "* In the 2nd phase, we use a small learning rate to find the best number of boosting rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-02 23:05:09,398] A new study created in memory with name: no-name-d3e86a77-6128-4028-906c-f1efcf3b8550\n",
      "[I 2025-04-02 23:05:09,470] Trial 0 finished with value: 16.114598998601426 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4195981825434215, 'reg_lambda': 0.5689344850030498, 'reg_alpha': 0.005224047812087992, 'max_depth': 4, 'min_child_weight': 12, 'subsample': 0.9330880728874675, 'colsample_bynode': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227, 'colsample_bylevel': 0.5102922471479012}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,620] Trial 1 finished with value: 16.613993120916373 and parameters: {'tree_method': 'approx', 'learning_rate': 0.26370173320348284, 'reg_lambda': 0.006867037309970066, 'reg_alpha': 0.006982943964830307, 'max_depth': 6, 'min_child_weight': 105, 'subsample': 0.7159725093210578, 'colsample_bynode': 0.645614570099021, 'colsample_bytree': 0.8059264473611898, 'colsample_bylevel': 0.569746930326021}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,648] Trial 2 finished with value: 17.532381590450996 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3368209952651108, 'reg_lambda': 4.106075002976849, 'reg_alpha': 0.008296801966462524, 'max_depth': 8, 'min_child_weight': 119, 'subsample': 0.5232252063599989, 'colsample_bynode': 0.8037724259507192, 'colsample_bytree': 0.5852620618436457, 'colsample_bylevel': 0.5325257964926398}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,710] Trial 3 finished with value: 16.5884864965403 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4425192044349383, 'reg_lambda': 0.025226142222995854, 'reg_alpha': 0.00281509417498869, 'max_depth': 9, 'min_child_weight': 89, 'subsample': 0.5610191174223894, 'colsample_bynode': 0.7475884550556351, 'colsample_bytree': 0.5171942605576092, 'colsample_bylevel': 0.954660201039391}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,799] Trial 4 finished with value: 17.36871935692553 and parameters: {'tree_method': 'hist', 'learning_rate': 0.2935133228268233, 'reg_lambda': 0.24739119193178508, 'reg_alpha': 0.3280903851909198, 'max_depth': 4, 'min_child_weight': 194, 'subsample': 0.8875664116805573, 'colsample_bynode': 0.9697494707820946, 'colsample_bytree': 0.9474136752138245, 'colsample_bylevel': 0.7989499894055425}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,906] Trial 5 finished with value: 16.231413433158764 and parameters: {'tree_method': 'approx', 'learning_rate': 0.2587948587257436, 'reg_lambda': 0.0016148742026634991, 'reg_alpha': 0.03141880762948323, 'max_depth': 6, 'min_child_weight': 55, 'subsample': 0.9143687545759647, 'colsample_bynode': 0.6783766633467947, 'colsample_bytree': 0.6404672548436904, 'colsample_bylevel': 0.7713480415791243}. Best is trial 0 with value: 16.114598998601426.\n",
      "[I 2025-04-02 23:05:09,911] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:09,914] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:09,917] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:09,922] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,029] Trial 10 finished with value: 15.717457099395077 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47257604771609946, 'reg_lambda': 0.4365329959343202, 'reg_alpha': 0.0012096552903479673, 'max_depth': 3, 'min_child_weight': 44, 'subsample': 0.9861488031179614, 'colsample_bynode': 0.5282255452552431, 'colsample_bytree': 0.977092324782823, 'colsample_bylevel': 0.6664659232646013}. Best is trial 10 with value: 15.717457099395077.\n",
      "[I 2025-04-02 23:05:10,122] Trial 11 pruned. Trial was pruned at iteration 68.\n",
      "[I 2025-04-02 23:05:10,154] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,185] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,283] Trial 14 finished with value: 15.629387436525578 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4308790299575487, 'reg_lambda': 0.13085269054669343, 'reg_alpha': 0.03137800548640157, 'max_depth': 10, 'min_child_weight': 24, 'subsample': 0.8308851073086485, 'colsample_bynode': 0.984634926024359, 'colsample_bytree': 0.9417531960252138, 'colsample_bylevel': 0.6271679595610379}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:10,313] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,344] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,413] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,446] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,561] Trial 19 finished with value: 16.00111111919784 and parameters: {'tree_method': 'hist', 'learning_rate': 0.33437954496173083, 'reg_lambda': 0.13286596259760916, 'reg_alpha': 0.012351206355435669, 'max_depth': 7, 'min_child_weight': 27, 'subsample': 0.86719553329466, 'colsample_bynode': 0.574608821936267, 'colsample_bytree': 0.8055662373253255, 'colsample_bylevel': 0.6244723918876194}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:10,595] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,637] Trial 21 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-02 23:05:10,746] Trial 22 finished with value: 15.868760883515238 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3603752400543475, 'reg_lambda': 0.1975291411603733, 'reg_alpha': 0.002782461547042498, 'max_depth': 9, 'min_child_weight': 22, 'subsample': 0.9521562873182934, 'colsample_bynode': 0.5440443443137871, 'colsample_bytree': 0.9534982722716281, 'colsample_bylevel': 0.6700501576639312}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:10,852] Trial 23 finished with value: 15.944989503925347 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36709234404429797, 'reg_lambda': 1.4158201018411496, 'reg_alpha': 0.002162049346735812, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9657162802607198, 'colsample_bynode': 0.6344033301804961, 'colsample_bytree': 0.9435849383457133, 'colsample_bylevel': 0.6928111279607773}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:10,885] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,918] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:10,957] Trial 26 pruned. Trial was pruned at iteration 7.\n",
      "[I 2025-04-02 23:05:10,990] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,023] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,122] Trial 29 finished with value: 16.28154805506447 and parameters: {'tree_method': 'hist', 'learning_rate': 0.41373376644409576, 'reg_lambda': 3.3786856451531797, 'reg_alpha': 0.005142209155433809, 'max_depth': 5, 'min_child_weight': 18, 'subsample': 0.9580060003755948, 'colsample_bynode': 0.8465077452539445, 'colsample_bytree': 0.8964280891263496, 'colsample_bylevel': 0.7157681732882473}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:11,287] Trial 30 finished with value: 15.988694603419708 and parameters: {'tree_method': 'hist', 'learning_rate': 0.443604537460608, 'reg_lambda': 0.04801342754683726, 'reg_alpha': 0.0021301490324276006, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9998937999354526, 'colsample_bynode': 0.799670118712667, 'colsample_bytree': 0.965846529956738, 'colsample_bylevel': 0.9907672213497579}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:11,397] Trial 31 finished with value: 16.093891400154305 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3593199414771894, 'reg_lambda': 1.4541037042690477, 'reg_alpha': 0.0021654194653825004, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9502485864325289, 'colsample_bynode': 0.6217016995925002, 'colsample_bytree': 0.9399888146347569, 'colsample_bylevel': 0.695609059254492}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:11,433] Trial 32 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:11,468] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,502] Trial 34 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,536] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,634] Trial 36 finished with value: 16.216423986136764 and parameters: {'tree_method': 'approx', 'learning_rate': 0.42012951992345565, 'reg_lambda': 5.504101746537027, 'reg_alpha': 0.0017586481433758757, 'max_depth': 8, 'min_child_weight': 12, 'subsample': 0.9339835498115091, 'colsample_bynode': 0.7652764355533851, 'colsample_bytree': 0.9700252487464953, 'colsample_bylevel': 0.7573178140349889}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:11,669] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,704] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,740] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,775] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:11,976] Trial 41 finished with value: 15.922295594799255 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4388519916785931, 'reg_lambda': 0.04922713617384557, 'reg_alpha': 0.002126350579909132, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9835560832201838, 'colsample_bynode': 0.8069505876106301, 'colsample_bytree': 0.96497734517997, 'colsample_bylevel': 0.9782080815273094}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:12,080] Trial 42 finished with value: 16.517610537516145 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4326545519843538, 'reg_lambda': 0.015256844844476425, 'reg_alpha': 0.0010685915411870134, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9406909609311261, 'colsample_bynode': 0.8062512335700058, 'colsample_bytree': 0.9278516697064573, 'colsample_bylevel': 0.9304515385864465}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:12,125] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,166] Trial 44 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-04-02 23:05:12,202] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,237] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,284] Trial 47 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:12,460] Trial 48 finished with value: 15.858774510922471 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47901571734891735, 'reg_lambda': 0.04634461285519717, 'reg_alpha': 0.05282751373165767, 'max_depth': 9, 'min_child_weight': 13, 'subsample': 0.5720610559589618, 'colsample_bynode': 0.8339732256906582, 'colsample_bytree': 0.9996229702696348, 'colsample_bylevel': 0.7482187044856975}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:12,497] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,533] Trial 50 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,570] Trial 51 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,607] Trial 52 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:12,644] Trial 53 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:12,838] Trial 54 finished with value: 15.780737075116784 and parameters: {'tree_method': 'hist', 'learning_rate': 0.44023664679290275, 'reg_lambda': 0.17937718439775852, 'reg_alpha': 0.0015022263263044725, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.742009223340298, 'colsample_bynode': 0.9598593467984249, 'colsample_bytree': 0.981154674369149, 'colsample_bylevel': 0.6533695304370056}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:12,974] Trial 55 finished with value: 16.15986239721259 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4424425833991898, 'reg_lambda': 0.17270500021700885, 'reg_alpha': 1.1265994626687765, 'max_depth': 7, 'min_child_weight': 25, 'subsample': 0.7339119480746423, 'colsample_bynode': 0.9548576774970189, 'colsample_bytree': 0.983870029271323, 'colsample_bylevel': 0.6099472989821473}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:13,011] Trial 56 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,049] Trial 57 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,086] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,123] Trial 59 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:13,221] Trial 60 finished with value: 16.359768994186798 and parameters: {'tree_method': 'hist', 'learning_rate': 0.460931046324997, 'reg_lambda': 0.22545677361879565, 'reg_alpha': 0.0314482325015354, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.7642317426942273, 'colsample_bynode': 0.811671069976794, 'colsample_bytree': 0.8992357456867729, 'colsample_bylevel': 0.677223718622327}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:13,341] Trial 61 finished with value: 15.975693010663985 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3966347844175787, 'reg_lambda': 2.147859121395278, 'reg_alpha': 0.0015135653578554756, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9454936421060797, 'colsample_bynode': 0.9685826487661368, 'colsample_bytree': 0.9533978344956678, 'colsample_bylevel': 0.6941672398037859}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:13,378] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,511] Trial 63 finished with value: 15.934186289347897 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4120861205561278, 'reg_lambda': 0.11511120781299888, 'reg_alpha': 0.0042607776075678895, 'max_depth': 9, 'min_child_weight': 18, 'subsample': 0.8477466777643037, 'colsample_bynode': 0.7476268446709925, 'colsample_bytree': 0.9246885265194716, 'colsample_bylevel': 0.6280807664731985}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:13,549] Trial 64 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:13,596] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,652] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,702] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,754] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,796] Trial 69 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-04-02 23:05:13,835] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:13,874] Trial 71 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:13,987] Trial 72 finished with value: 16.041339749125246 and parameters: {'tree_method': 'hist', 'learning_rate': 0.37610786998724144, 'reg_lambda': 0.6223485816759116, 'reg_alpha': 0.002546560739838575, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9686695086623756, 'colsample_bynode': 0.5205170778671082, 'colsample_bytree': 0.939079376478611, 'colsample_bylevel': 0.7129593748579393}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:14,024] Trial 73 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,061] Trial 74 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,098] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,136] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,174] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,211] Trial 78 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,249] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,287] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,427] Trial 81 finished with value: 15.943697370773842 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3975795027033334, 'reg_lambda': 2.1897191708488384, 'reg_alpha': 0.0016837543427204184, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9561420592664456, 'colsample_bynode': 0.9595666824497694, 'colsample_bytree': 0.9565808650164652, 'colsample_bylevel': 0.6968838536166817}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:14,466] Trial 82 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,504] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,603] Trial 84 finished with value: 15.820050662437449 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3891193925749359, 'reg_lambda': 3.8086724386892628, 'reg_alpha': 0.0016925838130150193, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.9733538822266862, 'colsample_bynode': 0.7651511695736642, 'colsample_bytree': 0.9819131677386363, 'colsample_bylevel': 0.7251900787043956}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:14,642] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,679] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,717] Trial 87 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,762] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,808] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,848] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,888] Trial 91 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,927] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:14,973] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,025] Trial 94 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:15,068] Trial 95 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,112] Trial 96 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:15,152] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,192] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,231] Trial 99 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,271] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,388] Trial 101 finished with value: 16.456723949768 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39951552694251896, 'reg_lambda': 1.9831603661790869, 'reg_alpha': 0.001589997376481648, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9469483309358132, 'colsample_bynode': 0.9833411119768003, 'colsample_bytree': 0.9611999365897014, 'colsample_bylevel': 0.6909308377858718}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:15,497] Trial 102 finished with value: 16.326904118886976 and parameters: {'tree_method': 'hist', 'learning_rate': 0.399532341848049, 'reg_lambda': 1.5149967406079254, 'reg_alpha': 0.0023611118198965625, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.9507573566721681, 'colsample_bynode': 0.9667814836965355, 'colsample_bytree': 0.9511674706598162, 'colsample_bylevel': 0.7148799425609031}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:15,537] Trial 103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,577] Trial 104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,620] Trial 105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,659] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,699] Trial 107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,739] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,783] Trial 109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,823] Trial 110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:15,995] Trial 111 finished with value: 16.381547276967854 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4474000608233314, 'reg_lambda': 0.05134971690211783, 'reg_alpha': 0.002151897047669751, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9994404484491867, 'colsample_bynode': 0.7996949708616891, 'colsample_bytree': 0.9575320959498315, 'colsample_bylevel': 0.9938028036517774}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:16,036] Trial 112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,153] Trial 113 finished with value: 16.475210830248777 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47264093967512955, 'reg_lambda': 0.08639707689461862, 'reg_alpha': 0.0032048381898242295, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9624624916200237, 'colsample_bynode': 0.7610422515790328, 'colsample_bytree': 0.9823624867122851, 'colsample_bylevel': 0.9607816514542169}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:16,291] Trial 114 finished with value: 16.112401039496774 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4831235596096699, 'reg_lambda': 0.06856860230919778, 'reg_alpha': 0.0020406776467920933, 'max_depth': 10, 'min_child_weight': 15, 'subsample': 0.9775020512809454, 'colsample_bynode': 0.8232092687412103, 'colsample_bytree': 0.9890656934424935, 'colsample_bylevel': 0.9784568828407099}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:16,331] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,372] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,412] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,453] Trial 118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,495] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,535] Trial 120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,576] Trial 121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,618] Trial 122 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:16,663] Trial 123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,790] Trial 124 finished with value: 16.058828332275116 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36512418407896813, 'reg_lambda': 0.058625263238949336, 'reg_alpha': 0.020719723182343844, 'max_depth': 12, 'min_child_weight': 17, 'subsample': 0.911187711478375, 'colsample_bynode': 0.9170143144135409, 'colsample_bytree': 0.9803643744569813, 'colsample_bylevel': 0.728311947223604}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:16,854] Trial 125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,902] Trial 126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,942] Trial 127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:16,982] Trial 128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,023] Trial 129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,064] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,107] Trial 131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,148] Trial 132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,190] Trial 133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,235] Trial 134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,278] Trial 135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,326] Trial 136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,370] Trial 137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,413] Trial 138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,454] Trial 139 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,510] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,553] Trial 141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,683] Trial 142 finished with value: 16.232899782831232 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3480461235681302, 'reg_lambda': 0.04016331500834777, 'reg_alpha': 0.016698250723457826, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.8684298773991657, 'colsample_bynode': 0.915749089348907, 'colsample_bytree': 0.8139254622727226, 'colsample_bylevel': 0.7302660092970327}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:17,731] Trial 143 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:17,775] Trial 144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,817] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,859] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,901] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,943] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:17,987] Trial 149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,028] Trial 150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,071] Trial 151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,114] Trial 152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,160] Trial 153 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-04-02 23:05:18,202] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,326] Trial 155 finished with value: 16.4025998737038 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36926090666033184, 'reg_lambda': 0.1496834789018161, 'reg_alpha': 0.0034859062582304704, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9906402221146722, 'colsample_bynode': 0.9890458241485365, 'colsample_bytree': 0.9631620544092234, 'colsample_bylevel': 0.7019125865024712}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:18,368] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,477] Trial 157 finished with value: 16.2274416297819 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39640651199834276, 'reg_lambda': 0.12651126343701155, 'reg_alpha': 0.0010075816877500958, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7072181568109379, 'colsample_bynode': 0.6592524971336395, 'colsample_bytree': 0.9718651961667126, 'colsample_bylevel': 0.7838425148858297}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:18,522] Trial 158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,565] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,606] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,649] Trial 161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,694] Trial 162 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:18,737] Trial 163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:18,842] Trial 164 finished with value: 16.401981547053406 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47252118850978964, 'reg_lambda': 0.06689341138313103, 'reg_alpha': 0.001203829569191347, 'max_depth': 10, 'min_child_weight': 15, 'subsample': 0.9708139354454857, 'colsample_bynode': 0.8413313602341976, 'colsample_bytree': 0.9772175828324042, 'colsample_bylevel': 0.9836380483099258}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:19,041] Trial 165 finished with value: 16.142639485468155 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4942785549760552, 'reg_lambda': 4.179994631172385, 'reg_alpha': 0.0018091176889081847, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.9610363015297154, 'colsample_bynode': 0.803824418856134, 'colsample_bytree': 0.9666614948070494, 'colsample_bylevel': 0.9706365201096192}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:19,085] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,129] Trial 167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,261] Trial 168 finished with value: 15.708391180628116 and parameters: {'tree_method': 'hist', 'learning_rate': 0.35465456677321866, 'reg_lambda': 0.17989796860206186, 'reg_alpha': 0.25449285646086, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8583284558677358, 'colsample_bynode': 0.9473458431776243, 'colsample_bytree': 0.7274685079597748, 'colsample_bylevel': 0.6629607191689394}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:19,400] Trial 169 finished with value: 16.17350804373985 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3549390313633273, 'reg_lambda': 0.2360329328792921, 'reg_alpha': 0.28767716438611773, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8165353508169131, 'colsample_bynode': 0.977977328213675, 'colsample_bytree': 0.949157836683359, 'colsample_bylevel': 0.6579554946814858}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:19,442] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,485] Trial 171 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:19,532] Trial 172 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:19,576] Trial 173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,622] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,666] Trial 175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,710] Trial 176 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,753] Trial 177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,802] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,847] Trial 179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,891] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,936] Trial 181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:19,980] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,025] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,070] Trial 184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,113] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,157] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,208] Trial 187 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:20,253] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,297] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,341] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,386] Trial 191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,435] Trial 192 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:20,573] Trial 193 finished with value: 16.18225263616356 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48655809851401793, 'reg_lambda': 4.476030930847095, 'reg_alpha': 0.0024423446043122746, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9480381897081457, 'colsample_bynode': 0.7919307602447523, 'colsample_bytree': 0.723140544796485, 'colsample_bylevel': 0.9998938057817688}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:20,619] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,737] Trial 195 finished with value: 16.119005017599267 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4824960304161529, 'reg_lambda': 1.037831827181214, 'reg_alpha': 0.0013915758090895392, 'max_depth': 8, 'min_child_weight': 12, 'subsample': 0.9328833668646412, 'colsample_bynode': 0.8272934008723276, 'colsample_bytree': 0.9581542383326673, 'colsample_bylevel': 0.9458486946861011}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:20,785] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,829] Trial 197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,873] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,920] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:20,965] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,120] Trial 201 finished with value: 16.2068536512846 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4991433389490591, 'reg_lambda': 0.05728059244641359, 'reg_alpha': 0.00195585229751072, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.9603108236638721, 'colsample_bynode': 0.8091883815320022, 'colsample_bytree': 0.9642074799575849, 'colsample_bylevel': 0.9800958550365896}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:21,329] Trial 202 finished with value: 16.232535896651836 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48594746350032175, 'reg_lambda': 0.6665584150820938, 'reg_alpha': 0.0010083788286362337, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9822359726229618, 'colsample_bynode': 0.8197922922203779, 'colsample_bytree': 0.9734155236994987, 'colsample_bylevel': 0.9722923616212445}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:21,375] Trial 203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,425] Trial 204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,471] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,516] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,561] Trial 207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,607] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,655] Trial 209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,701] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,747] Trial 211 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,792] Trial 212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,839] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,885] Trial 214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,932] Trial 215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:21,980] Trial 216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,027] Trial 217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,074] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,121] Trial 219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,169] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,222] Trial 221 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:22,338] Trial 222 finished with value: 16.222912987308984 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3558824684978593, 'reg_lambda': 0.2301079415816624, 'reg_alpha': 0.11758913299773227, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8394602365208133, 'colsample_bynode': 0.9787777328064613, 'colsample_bytree': 0.9636949183593372, 'colsample_bylevel': 0.6578457556546513}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:22,388] Trial 223 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:22,437] Trial 224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,486] Trial 225 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:22,543] Trial 226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,590] Trial 227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,638] Trial 228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,685] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:22,739] Trial 230 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:22,938] Trial 231 finished with value: 16.16193768254276 and parameters: {'tree_method': 'hist', 'learning_rate': 0.487081008337762, 'reg_lambda': 3.9006339103881658, 'reg_alpha': 0.0022565631725038676, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9462235046747389, 'colsample_bynode': 0.7954457877601583, 'colsample_bytree': 0.9982105511916995, 'colsample_bylevel': 0.9959130275192936}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:22,987] Trial 232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,035] Trial 233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,085] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,149] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,315] Trial 236 finished with value: 15.969846463591447 and parameters: {'tree_method': 'hist', 'learning_rate': 0.38008144351262324, 'reg_lambda': 2.021880988058694, 'reg_alpha': 0.0022574161100307466, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8769862376873846, 'colsample_bynode': 0.7735648877658802, 'colsample_bytree': 0.9992772007267174, 'colsample_bylevel': 0.7151220060166438}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:23,364] Trial 237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,413] Trial 238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,462] Trial 239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,511] Trial 240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,559] Trial 241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,608] Trial 242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,656] Trial 243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,706] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,755] Trial 245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,821] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,887] Trial 247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:23,956] Trial 248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,007] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,055] Trial 250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,104] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,153] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,202] Trial 253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,254] Trial 254 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:24,379] Trial 255 finished with value: 15.841695161811547 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36520035446490895, 'reg_lambda': 0.7794253642863805, 'reg_alpha': 0.0014705752667206258, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9713115321970484, 'colsample_bynode': 0.5440633847010414, 'colsample_bytree': 0.9651768165989911, 'colsample_bylevel': 0.6370000089153103}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:24,428] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,477] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,525] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,663] Trial 259 finished with value: 15.757754624140974 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42861067400466024, 'reg_lambda': 1.4013076318651179, 'reg_alpha': 0.0010384061508670358, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9501610489849266, 'colsample_bynode': 0.5622788928121131, 'colsample_bytree': 0.9905429272227081, 'colsample_bylevel': 0.621286181361264}. Best is trial 14 with value: 15.629387436525578.\n",
      "[I 2025-04-02 23:05:24,712] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,761] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,811] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,866] Trial 263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,915] Trial 264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:24,965] Trial 265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,015] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,068] Trial 267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,117] Trial 268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,167] Trial 269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,222] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,279] Trial 271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,329] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,379] Trial 273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,429] Trial 274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,482] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,531] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,581] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,631] Trial 278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,681] Trial 279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,730] Trial 280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,780] Trial 281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,832] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,887] Trial 283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,939] Trial 284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:25,989] Trial 285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,038] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,089] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,139] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,190] Trial 289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,240] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,289] Trial 291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,358] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,408] Trial 293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,462] Trial 294 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:26,514] Trial 295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,565] Trial 296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,618] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,670] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,721] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,773] Trial 300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,825] Trial 301 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:26,879] Trial 302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,931] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:26,982] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,036] Trial 305 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:27,088] Trial 306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,140] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,194] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,245] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,299] Trial 310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,362] Trial 311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,415] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,470] Trial 313 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:27,532] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,588] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,643] Trial 316 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:27,694] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,746] Trial 318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,799] Trial 319 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:27,853] Trial 320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,909] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:27,962] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,014] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,070] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,124] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,191] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,245] Trial 327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,297] Trial 328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,357] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,411] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,464] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,521] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,589] Trial 333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,651] Trial 334 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:28,705] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,759] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,813] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,867] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,920] Trial 339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:28,974] Trial 340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,027] Trial 341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,081] Trial 342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,136] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,191] Trial 344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,245] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,298] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,357] Trial 347 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:29,419] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,474] Trial 349 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:29,528] Trial 350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,581] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,635] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,689] Trial 353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,743] Trial 354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,800] Trial 355 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:29,854] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,909] Trial 357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:29,962] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,016] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,074] Trial 360 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:30,130] Trial 361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,185] Trial 362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,242] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,296] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,353] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,408] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,462] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,518] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,573] Trial 369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,629] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,686] Trial 371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,742] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,797] Trial 373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,853] Trial 374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,913] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:30,970] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,025] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,080] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,135] Trial 379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,191] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,248] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,304] Trial 382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,374] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,463] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,522] Trial 385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,578] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,634] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,690] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,746] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,805] Trial 390 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,862] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:31,925] Trial 392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,053] Trial 393 finished with value: 15.611515476087474 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4417553566833256, 'reg_lambda': 0.05510686954783215, 'reg_alpha': 0.00220230382047826, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.964242568622113, 'colsample_bynode': 0.984838207795654, 'colsample_bytree': 0.912441407854134, 'colsample_bylevel': 0.9901940478986758}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:32,110] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,166] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,222] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,278] Trial 397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,336] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,503] Trial 399 finished with value: 16.134261784305078 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3113699594891685, 'reg_lambda': 0.05848024834860574, 'reg_alpha': 0.17326807913266667, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9806305099421755, 'colsample_bynode': 0.9872265027571465, 'colsample_bytree': 0.9027296761384931, 'colsample_bylevel': 0.9484641926841441}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:32,680] Trial 400 finished with value: 15.695730456008027 and parameters: {'tree_method': 'hist', 'learning_rate': 0.33125192279613574, 'reg_lambda': 0.053525541448123125, 'reg_alpha': 0.16799011835155878, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9904873832342762, 'colsample_bynode': 0.9887356333260355, 'colsample_bytree': 0.8880736057953003, 'colsample_bylevel': 0.9047479163027662}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:32,739] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:32,892] Trial 402 finished with value: 16.21810357984662 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3300227482195034, 'reg_lambda': 0.029978845107432588, 'reg_alpha': 0.003777124979726751, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9945818536766974, 'colsample_bynode': 0.9997740711535703, 'colsample_bytree': 0.9203772376888516, 'colsample_bylevel': 0.9290134004051236}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:32,954] Trial 403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,011] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,068] Trial 405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,127] Trial 406 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:33,184] Trial 407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,242] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,300] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,357] Trial 410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,415] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,472] Trial 412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,542] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,708] Trial 414 finished with value: 15.822036122468015 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3546003945938317, 'reg_lambda': 0.052445920247483874, 'reg_alpha': 0.0015874310356376125, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9996075720176923, 'colsample_bynode': 0.9837014268439601, 'colsample_bytree': 0.926181873119291, 'colsample_bylevel': 0.9034371190119355}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:33,779] Trial 415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,838] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:33,898] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,007] Trial 418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,085] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,161] Trial 420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,223] Trial 421 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:34,291] Trial 422 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:34,350] Trial 423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,412] Trial 424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,470] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,529] Trial 426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,589] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,647] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,712] Trial 429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,772] Trial 430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,832] Trial 431 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:34,892] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:34,957] Trial 433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,015] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,073] Trial 435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,132] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,194] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,255] Trial 438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,314] Trial 439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,386] Trial 440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,455] Trial 441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,513] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,601] Trial 443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,661] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:35,791] Trial 445 finished with value: 15.674295584694727 and parameters: {'tree_method': 'hist', 'learning_rate': 0.2958946838225661, 'reg_lambda': 1.438195364697478, 'reg_alpha': 0.006733395380974809, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9993799130939994, 'colsample_bynode': 0.5235426987314767, 'colsample_bytree': 0.9243626171865104, 'colsample_bylevel': 0.6829184020155923}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:35,918] Trial 446 finished with value: 16.067476075950367 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36874176841155104, 'reg_lambda': 1.3718524682331303, 'reg_alpha': 0.009026013963260778, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9974096118724837, 'colsample_bynode': 0.5255593825029327, 'colsample_bytree': 0.9215772602847637, 'colsample_bylevel': 0.6874446118187373}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:35,984] Trial 447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,044] Trial 448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,105] Trial 449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,166] Trial 450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,295] Trial 451 finished with value: 15.884831946166301 and parameters: {'tree_method': 'hist', 'learning_rate': 0.36331769061353614, 'reg_lambda': 1.3852454889880743, 'reg_alpha': 0.0014557779582789845, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9975708535382205, 'colsample_bynode': 0.5365278265139565, 'colsample_bytree': 0.914352766535167, 'colsample_bylevel': 0.6959323557709023}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:36,355] Trial 452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,416] Trial 453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,496] Trial 454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,624] Trial 455 finished with value: 15.878643679195054 and parameters: {'tree_method': 'hist', 'learning_rate': 0.37391953453471183, 'reg_lambda': 1.307627290481029, 'reg_alpha': 0.0077475969974675285, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9855588339213048, 'colsample_bynode': 0.5289115183417433, 'colsample_bytree': 0.9173534727352395, 'colsample_bylevel': 0.6814887510467371}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:36,767] Trial 456 finished with value: 15.677618388690696 and parameters: {'tree_method': 'hist', 'learning_rate': 0.37414897981956785, 'reg_lambda': 1.1276534944578, 'reg_alpha': 0.013614515752643441, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9823715520287524, 'colsample_bynode': 0.5373160069570153, 'colsample_bytree': 0.9010597575791418, 'colsample_bylevel': 0.6670030895840828}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:36,829] Trial 457 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:36,891] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,024] Trial 459 finished with value: 15.808055267844058 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3763146914763255, 'reg_lambda': 0.7979792677158859, 'reg_alpha': 0.0064152565705959, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9876099433725989, 'colsample_bynode': 0.5487233593312646, 'colsample_bytree': 0.9160774876516788, 'colsample_bylevel': 0.6731339701017753}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:37,085] Trial 460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,145] Trial 461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,205] Trial 462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,266] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,326] Trial 464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,387] Trial 465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,450] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,513] Trial 467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,575] Trial 468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,651] Trial 469 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,718] Trial 470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,779] Trial 471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,840] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,901] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:37,962] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,028] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,089] Trial 476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,151] Trial 477 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:38,292] Trial 478 finished with value: 15.671838472063238 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3800407871240823, 'reg_lambda': 1.7658119356649282, 'reg_alpha': 0.0015585490947915772, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9696409687103019, 'colsample_bynode': 0.5244668475402947, 'colsample_bytree': 0.7120496113992211, 'colsample_bylevel': 0.6308339032275823}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:38,357] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,419] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,480] Trial 481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,541] Trial 482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,602] Trial 483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,663] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,725] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,787] Trial 486 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,847] Trial 487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,909] Trial 488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:38,987] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,064] Trial 490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,125] Trial 491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,196] Trial 492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,261] Trial 493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,323] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,399] Trial 495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,468] Trial 496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,531] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,601] Trial 498 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:39,734] Trial 499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,799] Trial 500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,861] Trial 501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,924] Trial 502 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:39,987] Trial 503 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,051] Trial 504 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,119] Trial 505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,184] Trial 506 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,247] Trial 507 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,391] Trial 508 finished with value: 15.897611563917584 and parameters: {'tree_method': 'hist', 'learning_rate': 0.38810686213985957, 'reg_lambda': 0.02156458942923481, 'reg_alpha': 0.005901746900799167, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9629092744236789, 'colsample_bynode': 0.9529289233035282, 'colsample_bytree': 0.8988576943509712, 'colsample_bylevel': 0.6939280471215523}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:40,455] Trial 509 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,519] Trial 510 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,581] Trial 511 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,712] Trial 512 finished with value: 15.975543161216368 and parameters: {'tree_method': 'hist', 'learning_rate': 0.38525917354203404, 'reg_lambda': 0.02093663189369886, 'reg_alpha': 0.007390690838275518, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.9514906488026046, 'colsample_bynode': 0.9539754291968867, 'colsample_bytree': 0.8961786064614342, 'colsample_bylevel': 0.6839535404173004}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:40,777] Trial 513 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,839] Trial 514 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,901] Trial 515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:40,963] Trial 516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,026] Trial 517 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,145] Trial 518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,209] Trial 519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,276] Trial 520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,340] Trial 521 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,403] Trial 522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,466] Trial 523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,551] Trial 524 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,615] Trial 525 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,681] Trial 526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,754] Trial 527 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:41,825] Trial 528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,888] Trial 529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:41,952] Trial 530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,014] Trial 531 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,082] Trial 532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,147] Trial 533 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,211] Trial 534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,274] Trial 535 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,383] Trial 536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,498] Trial 537 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,662] Trial 538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,733] Trial 539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,799] Trial 540 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,865] Trial 541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,929] Trial 542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:42,999] Trial 543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,064] Trial 544 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,128] Trial 545 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,371] Trial 546 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,460] Trial 547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,529] Trial 548 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,594] Trial 549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,659] Trial 550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,726] Trial 551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,793] Trial 552 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:43,973] Trial 553 finished with value: 15.805685034116829 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4010796333702591, 'reg_lambda': 0.2035777115137454, 'reg_alpha': 0.002481708168777278, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9991393232803866, 'colsample_bynode': 0.5325212432466423, 'colsample_bytree': 0.9661913092309368, 'colsample_bylevel': 0.6734091426406446}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:44,128] Trial 554 finished with value: 15.81244050164278 and parameters: {'tree_method': 'hist', 'learning_rate': 0.41226615109205444, 'reg_lambda': 0.5149189709291927, 'reg_alpha': 0.0027454929543203137, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9929900299918037, 'colsample_bynode': 0.5341886494142056, 'colsample_bytree': 0.9650802064308674, 'colsample_bylevel': 0.6579625399686037}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:44,207] Trial 555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,392] Trial 556 finished with value: 15.780809732802071 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4097780196987834, 'reg_lambda': 0.5509274023550316, 'reg_alpha': 0.002690571459717359, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9908726308902208, 'colsample_bynode': 0.5356877347992286, 'colsample_bytree': 0.9653165257113868, 'colsample_bylevel': 0.6599425110387371}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:44,467] Trial 557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,534] Trial 558 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,603] Trial 559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,743] Trial 560 finished with value: 15.914333115779055 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4152430805338785, 'reg_lambda': 0.5934256339445297, 'reg_alpha': 0.003560441752648747, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9998744516406788, 'colsample_bynode': 0.541224365427864, 'colsample_bytree': 0.9753645994329003, 'colsample_bylevel': 0.6630455999408901}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:44,820] Trial 561 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,889] Trial 562 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:44,956] Trial 563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,023] Trial 564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,091] Trial 565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,158] Trial 566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,224] Trial 567 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,292] Trial 568 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,358] Trial 569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,497] Trial 570 finished with value: 15.703844730878645 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4067080928371721, 'reg_lambda': 0.3231572508356569, 'reg_alpha': 0.002839013097779848, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9803843176601512, 'colsample_bynode': 0.5336107375485498, 'colsample_bytree': 0.9653548510138421, 'colsample_bylevel': 0.660916414154687}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:45,636] Trial 571 finished with value: 15.733907580308543 and parameters: {'tree_method': 'hist', 'learning_rate': 0.40380217914241606, 'reg_lambda': 0.30611289804613484, 'reg_alpha': 0.00244338287857228, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9819054543338928, 'colsample_bynode': 0.5320049012403993, 'colsample_bytree': 0.9645969068869955, 'colsample_bylevel': 0.6600440447490782}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:45,778] Trial 572 finished with value: 15.973304802522158 and parameters: {'tree_method': 'hist', 'learning_rate': 0.40484254698580757, 'reg_lambda': 0.2700845687576788, 'reg_alpha': 0.0028844957526577165, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9811646092354499, 'colsample_bynode': 0.5334728797216043, 'colsample_bytree': 0.9642636839650602, 'colsample_bylevel': 0.6610646741754449}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:45,845] Trial 573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,910] Trial 574 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:45,999] Trial 575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,068] Trial 576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,139] Trial 577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,206] Trial 578 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,373] Trial 579 finished with value: 15.815446219056108 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4118956928150779, 'reg_lambda': 0.43944731708107265, 'reg_alpha': 0.1083570267629413, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9778413107143149, 'colsample_bynode': 0.538621572937138, 'colsample_bytree': 0.9750781623189011, 'colsample_bylevel': 0.6734358577763392}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:46,442] Trial 580 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,508] Trial 581 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,595] Trial 582 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:46,661] Trial 583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,729] Trial 584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,798] Trial 585 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,864] Trial 586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:46,935] Trial 587 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:47,003] Trial 588 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,070] Trial 589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,139] Trial 590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,306] Trial 591 finished with value: 16.018088451928296 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3949303150770428, 'reg_lambda': 0.2102633873530334, 'reg_alpha': 0.046669568535547525, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9690227599381913, 'colsample_bynode': 0.5333326420917024, 'colsample_bytree': 0.9749328021844591, 'colsample_bylevel': 0.7820174540236593}. Best is trial 393 with value: 15.611515476087474.\n",
      "[I 2025-04-02 23:05:47,374] Trial 592 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,446] Trial 593 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,515] Trial 594 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:47,582] Trial 595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:47,774] Trial 596 finished with value: 15.462780628158827 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39256494225684785, 'reg_lambda': 0.24051223934841084, 'reg_alpha': 0.0012994001124566374, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9668763296113029, 'colsample_bynode': 0.529147548611789, 'colsample_bytree': 0.7010668264948283, 'colsample_bylevel': 0.6690571781513444}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:47,954] Trial 597 finished with value: 15.830144259610353 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3957220243137935, 'reg_lambda': 0.25909452797626137, 'reg_alpha': 0.0011593137275449257, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9815239839458749, 'colsample_bynode': 0.528877113157432, 'colsample_bytree': 0.6806087235922322, 'colsample_bylevel': 0.6639012877077769}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:48,030] Trial 598 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,199] Trial 599 finished with value: 16.01883054637988 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39508959484111394, 'reg_lambda': 0.2646810186123088, 'reg_alpha': 0.0010147038331121618, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9687973766551404, 'colsample_bynode': 0.5249127719326079, 'colsample_bytree': 0.6816679760646447, 'colsample_bylevel': 0.6557922062789193}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:48,267] Trial 600 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,333] Trial 601 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,400] Trial 602 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,466] Trial 603 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,541] Trial 604 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:48,610] Trial 605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,685] Trial 606 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,753] Trial 607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,821] Trial 608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,890] Trial 609 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:48,958] Trial 610 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,029] Trial 611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,097] Trial 612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,167] Trial 613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,235] Trial 614 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,383] Trial 615 finished with value: 15.630288446126912 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4711030025360655, 'reg_lambda': 0.17218601403121347, 'reg_alpha': 0.29510675533780956, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9822522295939065, 'colsample_bynode': 0.5275270905788092, 'colsample_bytree': 0.7010831977036681, 'colsample_bylevel': 0.6591116186141251}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:49,452] Trial 616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,599] Trial 617 finished with value: 16.000848930904517 and parameters: {'tree_method': 'hist', 'learning_rate': 0.46622885785684537, 'reg_lambda': 0.22737775092211243, 'reg_alpha': 0.330090271195901, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9742282184674982, 'colsample_bynode': 0.5689980461349273, 'colsample_bytree': 0.7233358948025095, 'colsample_bylevel': 0.6546257567094106}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:49,669] Trial 618 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:49,741] Trial 619 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:49,818] Trial 620 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,900] Trial 621 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:49,969] Trial 622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,044] Trial 623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,116] Trial 624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,206] Trial 625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,275] Trial 626 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,346] Trial 627 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,416] Trial 628 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,485] Trial 629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,555] Trial 630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,623] Trial 631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,692] Trial 632 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,766] Trial 633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,835] Trial 634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,905] Trial 635 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:50,976] Trial 636 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,045] Trial 637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,122] Trial 638 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,193] Trial 639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,264] Trial 640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,335] Trial 641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,407] Trial 642 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:51,479] Trial 643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,549] Trial 644 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,643] Trial 645 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,715] Trial 646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,789] Trial 647 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,899] Trial 648 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:51,973] Trial 649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,045] Trial 650 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,115] Trial 651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,211] Trial 652 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,284] Trial 653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,356] Trial 654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,427] Trial 655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,559] Trial 656 finished with value: 16.194301078533588 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42147254250305344, 'reg_lambda': 0.718225586896415, 'reg_alpha': 0.12360997647035102, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.9644258785629736, 'colsample_bynode': 0.5530186661291997, 'colsample_bytree': 0.6869837276638247, 'colsample_bylevel': 0.7529526270907625}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:52,629] Trial 657 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,699] Trial 658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,780] Trial 659 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,853] Trial 660 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,924] Trial 661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:52,998] Trial 662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,069] Trial 663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,139] Trial 664 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,211] Trial 665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,285] Trial 666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,355] Trial 667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,429] Trial 668 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,499] Trial 669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,570] Trial 670 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,649] Trial 671 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:53,792] Trial 672 finished with value: 15.650062275557982 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4800363620144902, 'reg_lambda': 0.6575610741311883, 'reg_alpha': 0.0014088609191982376, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9874490576084397, 'colsample_bynode': 0.5431120147789498, 'colsample_bytree': 0.9515056275251944, 'colsample_bylevel': 0.6712034717944334}. Best is trial 596 with value: 15.462780628158827.\n",
      "[I 2025-04-02 23:05:53,868] Trial 673 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:54,011] Trial 674 finished with value: 15.289912735174598 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48745128386892783, 'reg_lambda': 0.7680382368547992, 'reg_alpha': 0.0014652444344312428, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9892856502454168, 'colsample_bynode': 0.5387881031191355, 'colsample_bytree': 0.9500367597154393, 'colsample_bylevel': 0.6743831576524036}. Best is trial 674 with value: 15.289912735174598.\n",
      "[I 2025-04-02 23:05:54,085] Trial 675 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,157] Trial 676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,245] Trial 677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,330] Trial 678 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:05:54,426] Trial 679 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,581] Trial 680 finished with value: 15.284709147154507 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39863956598229794, 'reg_lambda': 0.92457064534831, 'reg_alpha': 0.0012465313132076418, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9908694324044368, 'colsample_bynode': 0.5695752146388356, 'colsample_bytree': 0.9555642472791113, 'colsample_bylevel': 0.6569817240771461}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:54,722] Trial 681 finished with value: 15.887415762486727 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4983707179951512, 'reg_lambda': 0.8799220250800992, 'reg_alpha': 0.001281667692634857, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9982197210575655, 'colsample_bynode': 0.5661513949372141, 'colsample_bytree': 0.9529718519084921, 'colsample_bylevel': 0.66378871384306}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:54,795] Trial 682 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,867] Trial 683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:54,941] Trial 684 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:55,013] Trial 685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,084] Trial 686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,156] Trial 687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,245] Trial 688 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,321] Trial 689 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,394] Trial 690 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,470] Trial 691 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,542] Trial 692 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,631] Trial 693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,704] Trial 694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,846] Trial 695 finished with value: 15.97600360472769 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4670638054270388, 'reg_lambda': 1.0206938895827138, 'reg_alpha': 0.0012066960818685028, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9907888593539941, 'colsample_bynode': 0.5349243064054963, 'colsample_bytree': 0.9711223633959631, 'colsample_bylevel': 0.6771277903738389}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:55,919] Trial 696 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:55,989] Trial 697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,061] Trial 698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,136] Trial 699 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,211] Trial 700 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,285] Trial 701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,369] Trial 702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,442] Trial 703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,514] Trial 704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,587] Trial 705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,691] Trial 706 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,765] Trial 707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,841] Trial 708 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,915] Trial 709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:56,990] Trial 710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,063] Trial 711 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,246] Trial 712 finished with value: 15.962768424834497 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4005481337382604, 'reg_lambda': 0.8116086859820393, 'reg_alpha': 0.003083190739662994, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9910977807217668, 'colsample_bynode': 0.5126092142225938, 'colsample_bytree': 0.6849407192851535, 'colsample_bylevel': 0.6687671752897592}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:57,320] Trial 713 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,392] Trial 714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,466] Trial 715 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,542] Trial 716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,615] Trial 717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,689] Trial 718 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,774] Trial 719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:57,930] Trial 720 finished with value: 15.970673824896954 and parameters: {'tree_method': 'approx', 'learning_rate': 0.4197071014812535, 'reg_lambda': 0.2645018465342869, 'reg_alpha': 0.0015076547292172068, 'max_depth': 11, 'min_child_weight': 11, 'subsample': 0.9899016239140435, 'colsample_bynode': 0.9888554131308598, 'colsample_bytree': 0.977320092684285, 'colsample_bylevel': 0.6599540396612181}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:58,005] Trial 721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,080] Trial 722 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,154] Trial 723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,236] Trial 724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,311] Trial 725 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,465] Trial 726 finished with value: 15.789806679360911 and parameters: {'tree_method': 'hist', 'learning_rate': 0.38991108916046874, 'reg_lambda': 0.5106707001008596, 'reg_alpha': 0.0025850407733987012, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9918673161642664, 'colsample_bynode': 0.5713858533073455, 'colsample_bytree': 0.9655378498218201, 'colsample_bylevel': 0.6521266651892922}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:58,539] Trial 727 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,613] Trial 728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,694] Trial 729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,769] Trial 730 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,843] Trial 731 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,916] Trial 732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:58,990] Trial 733 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,126] Trial 734 finished with value: 15.990291458879152 and parameters: {'tree_method': 'hist', 'learning_rate': 0.41693468641174314, 'reg_lambda': 1.028278437770069, 'reg_alpha': 0.0024188651322024834, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9649086008033287, 'colsample_bynode': 0.5892732799515874, 'colsample_bytree': 0.9411340412559843, 'colsample_bylevel': 0.6579872775855367}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:05:59,203] Trial 735 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,281] Trial 736 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,357] Trial 737 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,433] Trial 738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,508] Trial 739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,584] Trial 740 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,659] Trial 741 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,735] Trial 742 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,810] Trial 743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:05:59,890] Trial 744 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:05:59,966] Trial 745 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,120] Trial 746 finished with value: 16.126253620705327 and parameters: {'tree_method': 'hist', 'learning_rate': 0.46917787505873143, 'reg_lambda': 0.5882514811257108, 'reg_alpha': 5.563949545756872, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.95914048424485, 'colsample_bynode': 0.5399966167097546, 'colsample_bytree': 0.9586288719308454, 'colsample_bylevel': 0.6714662171180584}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:00,196] Trial 747 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,276] Trial 748 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,350] Trial 749 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,440] Trial 750 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,524] Trial 751 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,601] Trial 752 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,703] Trial 753 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,780] Trial 754 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:00,866] Trial 755 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:00,942] Trial 756 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,034] Trial 757 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,112] Trial 758 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,194] Trial 759 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,348] Trial 760 finished with value: 15.789804487870224 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4135504303751976, 'reg_lambda': 0.6793087910808735, 'reg_alpha': 0.3503355802308732, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9879221513623903, 'colsample_bynode': 0.5486338334213323, 'colsample_bytree': 0.9539879072348466, 'colsample_bylevel': 0.691566900127148}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:01,423] Trial 761 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,499] Trial 762 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,639] Trial 763 finished with value: 15.899621954253616 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42779271093607446, 'reg_lambda': 0.6053643176746203, 'reg_alpha': 0.5413470762717301, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9787298281469434, 'colsample_bynode': 0.6033307043318563, 'colsample_bytree': 0.9537439192033491, 'colsample_bylevel': 0.6838423564740391}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:01,746] Trial 764 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:01,824] Trial 765 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,902] Trial 766 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:01,978] Trial 767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,057] Trial 768 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,138] Trial 769 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:02,215] Trial 770 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,299] Trial 771 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,375] Trial 772 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,456] Trial 773 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:02,540] Trial 774 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,617] Trial 775 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,695] Trial 776 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:02,777] Trial 777 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,867] Trial 778 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:02,946] Trial 779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,027] Trial 780 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:03,105] Trial 781 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,182] Trial 782 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,262] Trial 783 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,343] Trial 784 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,421] Trial 785 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,498] Trial 786 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,574] Trial 787 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,652] Trial 788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,731] Trial 789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,811] Trial 790 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,892] Trial 791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:03,970] Trial 792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,050] Trial 793 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,129] Trial 794 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,208] Trial 795 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,287] Trial 796 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,370] Trial 797 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,449] Trial 798 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,538] Trial 799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,657] Trial 800 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,748] Trial 801 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:04,825] Trial 802 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,905] Trial 803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:04,982] Trial 804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,060] Trial 805 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,137] Trial 806 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,215] Trial 807 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,298] Trial 808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,378] Trial 809 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,459] Trial 810 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,646] Trial 811 finished with value: 15.865950885678068 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3782047033438634, 'reg_lambda': 0.41235707699370766, 'reg_alpha': 0.2036254459493401, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9710850431187202, 'colsample_bynode': 0.5231950505061492, 'colsample_bytree': 0.9607114135414286, 'colsample_bylevel': 0.6788024044715515}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:05,724] Trial 812 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,801] Trial 813 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,887] Trial 814 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:05,966] Trial 815 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,055] Trial 816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,215] Trial 817 finished with value: 16.1881886653073 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4428155545024196, 'reg_lambda': 1.116646604343331, 'reg_alpha': 0.0014373752231554044, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9744716969403626, 'colsample_bynode': 0.5467370884570167, 'colsample_bytree': 0.9336237090302039, 'colsample_bylevel': 0.6459484543692716}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:06,304] Trial 818 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,387] Trial 819 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:06,475] Trial 820 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,621] Trial 821 finished with value: 16.09274027078654 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4189053493248921, 'reg_lambda': 0.8838104856056326, 'reg_alpha': 0.001000937108650727, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9706662139012592, 'colsample_bynode': 0.5243248253588284, 'colsample_bytree': 0.9540428819195015, 'colsample_bylevel': 0.6594452418376967}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:06,722] Trial 822 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,824] Trial 823 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,905] Trial 824 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:06,987] Trial 825 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,129] Trial 826 finished with value: 15.84797319950466 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42929040945172586, 'reg_lambda': 0.5696921655498797, 'reg_alpha': 0.0026476608779238157, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9758382378730577, 'colsample_bynode': 0.5311380276655213, 'colsample_bytree': 0.999226170205788, 'colsample_bylevel': 0.648453437469812}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:07,208] Trial 827 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,286] Trial 828 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,370] Trial 829 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,451] Trial 830 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,532] Trial 831 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,618] Trial 832 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,705] Trial 833 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,894] Trial 834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:07,978] Trial 835 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,059] Trial 836 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,147] Trial 837 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,228] Trial 838 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,308] Trial 839 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,389] Trial 840 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:08,934] Trial 841 finished with value: 15.5258395884353 and parameters: {'tree_method': 'hist', 'learning_rate': 0.43455311408507663, 'reg_lambda': 0.5944382101198558, 'reg_alpha': 0.2499449613307329, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9824676003842705, 'colsample_bynode': 0.5669751687451065, 'colsample_bytree': 0.9220100032442137, 'colsample_bylevel': 0.6615100661298463}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:09,018] Trial 842 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:09,181] Trial 843 finished with value: 15.879024115398702 and parameters: {'tree_method': 'hist', 'learning_rate': 0.43960446275816834, 'reg_lambda': 0.4818382729122806, 'reg_alpha': 0.37908396447670933, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.9906796303475777, 'colsample_bynode': 0.5714787611840011, 'colsample_bytree': 0.9091917116974214, 'colsample_bylevel': 0.6366122168243588}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:09,263] Trial 844 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,343] Trial 845 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,424] Trial 846 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,504] Trial 847 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,588] Trial 848 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,668] Trial 849 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,750] Trial 850 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,831] Trial 851 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,913] Trial 852 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:09,993] Trial 853 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,075] Trial 854 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,162] Trial 855 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,243] Trial 856 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,323] Trial 857 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,408] Trial 858 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,489] Trial 859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,570] Trial 860 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,648] Trial 861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,727] Trial 862 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,804] Trial 863 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,896] Trial 864 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:10,992] Trial 865 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,073] Trial 866 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:11,153] Trial 867 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,232] Trial 868 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,314] Trial 869 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:11,399] Trial 870 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,487] Trial 871 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,573] Trial 872 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,682] Trial 873 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,764] Trial 874 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:11,931] Trial 875 finished with value: 15.824066317589097 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48465072687597915, 'reg_lambda': 0.0859764809608995, 'reg_alpha': 0.00119022027949006, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9591880439974224, 'colsample_bynode': 0.5551710424984933, 'colsample_bytree': 0.6919857523914715, 'colsample_bylevel': 0.9256815884630218}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:12,014] Trial 876 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,095] Trial 877 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,216] Trial 878 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,297] Trial 879 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,378] Trial 880 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,459] Trial 881 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,561] Trial 882 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,647] Trial 883 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,728] Trial 884 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,809] Trial 885 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,906] Trial 886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:12,998] Trial 887 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,082] Trial 888 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,165] Trial 889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,247] Trial 890 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,329] Trial 891 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,417] Trial 892 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,497] Trial 893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,580] Trial 894 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,663] Trial 895 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,748] Trial 896 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,830] Trial 897 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:13,913] Trial 898 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:13,997] Trial 899 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,079] Trial 900 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,169] Trial 901 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,257] Trial 902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,341] Trial 903 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,428] Trial 904 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,510] Trial 905 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,593] Trial 906 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:14,678] Trial 907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,203] Trial 908 finished with value: 15.736993363210388 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4103180068882655, 'reg_lambda': 0.441884852481051, 'reg_alpha': 0.0019196149386602598, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9907653364560928, 'colsample_bynode': 0.5417052597150419, 'colsample_bytree': 0.9590945301551053, 'colsample_bylevel': 0.6526637381588958}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:15,314] Trial 909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,436] Trial 910 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,519] Trial 911 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,602] Trial 912 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,686] Trial 913 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,772] Trial 914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,872] Trial 915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:15,981] Trial 916 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,065] Trial 917 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,148] Trial 918 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,302] Trial 919 finished with value: 15.948333401388831 and parameters: {'tree_method': 'hist', 'learning_rate': 0.49628670556826576, 'reg_lambda': 1.7852754771106494, 'reg_alpha': 0.002427868240218807, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9906463717759973, 'colsample_bynode': 0.5314992424045745, 'colsample_bytree': 0.9632699930697021, 'colsample_bylevel': 0.6579443965543103}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:16,388] Trial 920 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,508] Trial 921 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,600] Trial 922 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,686] Trial 923 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,775] Trial 924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:16,963] Trial 925 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,079] Trial 926 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:17,260] Trial 927 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,396] Trial 928 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,482] Trial 929 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,566] Trial 930 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,651] Trial 931 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:17,735] Trial 932 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,821] Trial 933 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:17,915] Trial 934 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,005] Trial 935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,089] Trial 936 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,179] Trial 937 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,268] Trial 938 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:18,360] Trial 939 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,445] Trial 940 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,531] Trial 941 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,617] Trial 942 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,705] Trial 943 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,790] Trial 944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,875] Trial 945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:18,961] Trial 946 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,048] Trial 947 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,136] Trial 948 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,221] Trial 949 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,316] Trial 950 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,417] Trial 951 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:19,505] Trial 952 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,590] Trial 953 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,677] Trial 954 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,763] Trial 955 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:19,855] Trial 956 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:19,942] Trial 957 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,029] Trial 958 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,115] Trial 959 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,203] Trial 960 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,297] Trial 961 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,385] Trial 962 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,479] Trial 963 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,566] Trial 964 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,654] Trial 965 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,739] Trial 966 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:20,985] Trial 967 finished with value: 16.18080653621023 and parameters: {'tree_method': 'approx', 'learning_rate': 0.4400758531389587, 'reg_lambda': 0.2675599956221827, 'reg_alpha': 0.0014497574849951574, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9489308252688274, 'colsample_bynode': 0.5593195071996041, 'colsample_bytree': 0.9609018242731794, 'colsample_bylevel': 0.6572697950338305}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:21,072] Trial 968 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,174] Trial 969 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,264] Trial 970 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,350] Trial 971 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,454] Trial 972 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,542] Trial 973 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,627] Trial 974 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,721] Trial 975 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,831] Trial 976 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:21,920] Trial 977 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,021] Trial 978 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,109] Trial 979 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,199] Trial 980 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,290] Trial 981 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,392] Trial 982 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,481] Trial 983 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,580] Trial 984 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,668] Trial 985 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,767] Trial 986 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,880] Trial 987 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:22,987] Trial 988 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,082] Trial 989 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,172] Trial 990 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,258] Trial 991 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,345] Trial 992 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,669] Trial 993 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,759] Trial 994 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,848] Trial 995 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:23,935] Trial 996 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,022] Trial 997 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,110] Trial 998 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,200] Trial 999 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,295] Trial 1000 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,387] Trial 1001 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,480] Trial 1002 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,572] Trial 1003 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,685] Trial 1004 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,776] Trial 1005 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,864] Trial 1006 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:24,970] Trial 1007 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,083] Trial 1008 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,171] Trial 1009 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,257] Trial 1010 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,350] Trial 1011 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:25,437] Trial 1012 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,532] Trial 1013 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,629] Trial 1014 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,717] Trial 1015 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,805] Trial 1016 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,894] Trial 1017 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:25,984] Trial 1018 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,073] Trial 1019 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,162] Trial 1020 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,251] Trial 1021 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,340] Trial 1022 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,433] Trial 1023 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,528] Trial 1024 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:26,620] Trial 1025 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,710] Trial 1026 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,802] Trial 1027 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,893] Trial 1028 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:26,982] Trial 1029 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,087] Trial 1030 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,180] Trial 1031 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,272] Trial 1032 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,360] Trial 1033 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,449] Trial 1034 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,542] Trial 1035 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,644] Trial 1036 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,732] Trial 1037 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,837] Trial 1038 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:27,939] Trial 1039 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:28,037] Trial 1040 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,133] Trial 1041 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,231] Trial 1042 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,319] Trial 1043 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,411] Trial 1044 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:28,505] Trial 1045 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:28,599] Trial 1046 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,688] Trial 1047 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,781] Trial 1048 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,870] Trial 1049 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:28,957] Trial 1050 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,047] Trial 1051 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,137] Trial 1052 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,225] Trial 1053 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,314] Trial 1054 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,406] Trial 1055 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,498] Trial 1056 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,593] Trial 1057 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,701] Trial 1058 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,793] Trial 1059 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:29,887] Trial 1060 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:29,981] Trial 1061 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,073] Trial 1062 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,169] Trial 1063 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,262] Trial 1064 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,355] Trial 1065 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,445] Trial 1066 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,548] Trial 1067 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:30,641] Trial 1068 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,733] Trial 1069 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,826] Trial 1070 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:30,919] Trial 1071 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,010] Trial 1072 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,100] Trial 1073 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,195] Trial 1074 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,290] Trial 1075 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,382] Trial 1076 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,478] Trial 1077 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,664] Trial 1078 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:31,998] Trial 1079 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,135] Trial 1080 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,229] Trial 1081 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,321] Trial 1082 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,502] Trial 1083 finished with value: 15.84263619680028 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4054595341279572, 'reg_lambda': 0.05214723128862646, 'reg_alpha': 0.7086581013482729, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9837381681770996, 'colsample_bynode': 0.5228121477283056, 'colsample_bytree': 0.9612685128555573, 'colsample_bylevel': 0.6711547854980505}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:32,597] Trial 1084 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,750] Trial 1085 finished with value: 16.047892672396475 and parameters: {'tree_method': 'hist', 'learning_rate': 0.499803810863119, 'reg_lambda': 1.0277563556738314, 'reg_alpha': 0.002130521765366195, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9909115812814192, 'colsample_bynode': 0.5566282840650021, 'colsample_bytree': 0.9751771669913554, 'colsample_bylevel': 0.6603456920892605}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:32,841] Trial 1086 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:32,933] Trial 1087 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,036] Trial 1088 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,129] Trial 1089 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,240] Trial 1090 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,334] Trial 1091 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,434] Trial 1092 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,529] Trial 1093 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,639] Trial 1094 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,735] Trial 1095 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,874] Trial 1096 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:33,970] Trial 1097 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:34,526] Trial 1098 finished with value: 15.590664791072815 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4684350413531586, 'reg_lambda': 1.1168212461776692, 'reg_alpha': 0.002098520875494014, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9799589904889682, 'colsample_bynode': 0.5168660032782203, 'colsample_bytree': 0.9649943615756869, 'colsample_bylevel': 0.6447738355163197}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:34,625] Trial 1099 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:34,718] Trial 1100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:34,811] Trial 1101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:34,903] Trial 1102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:34,996] Trial 1103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,102] Trial 1104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,237] Trial 1105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,429] Trial 1106 finished with value: 15.95672613336909 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4790458975062206, 'reg_lambda': 1.0956742842202556, 'reg_alpha': 0.001609750174112606, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9655682019353349, 'colsample_bynode': 0.5223527645675765, 'colsample_bytree': 0.685746451529009, 'colsample_bylevel': 0.6461957414177396}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:35,527] Trial 1107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,625] Trial 1108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,720] Trial 1109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,813] Trial 1110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:35,910] Trial 1111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,004] Trial 1112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,098] Trial 1113 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,191] Trial 1114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,284] Trial 1115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,381] Trial 1116 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:36,476] Trial 1117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,572] Trial 1118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,666] Trial 1119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,764] Trial 1120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,862] Trial 1121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:36,958] Trial 1122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,057] Trial 1123 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:37,173] Trial 1124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,271] Trial 1125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,368] Trial 1126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,466] Trial 1127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,561] Trial 1128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,663] Trial 1129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,760] Trial 1130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,853] Trial 1131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:37,960] Trial 1132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,064] Trial 1133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,160] Trial 1134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,254] Trial 1135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,349] Trial 1136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,446] Trial 1137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,541] Trial 1138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,652] Trial 1139 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,747] Trial 1140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:38,931] Trial 1141 finished with value: 15.693720935254346 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39554017978702866, 'reg_lambda': 0.6398192405902456, 'reg_alpha': 0.0017690202197256097, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9706179348314619, 'colsample_bynode': 0.572221283935814, 'colsample_bytree': 0.9416519825326981, 'colsample_bylevel': 0.6780606909293577}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:39,039] Trial 1142 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,135] Trial 1143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,231] Trial 1144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,330] Trial 1145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,438] Trial 1146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,539] Trial 1147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,640] Trial 1148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,734] Trial 1149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,828] Trial 1150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:39,930] Trial 1151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,044] Trial 1152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,139] Trial 1153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,254] Trial 1154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,365] Trial 1155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,473] Trial 1156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,603] Trial 1157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,718] Trial 1158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:40,846] Trial 1159 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:40,965] Trial 1160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,072] Trial 1161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,175] Trial 1162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,278] Trial 1163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,395] Trial 1164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,498] Trial 1165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,597] Trial 1166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,766] Trial 1167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,882] Trial 1168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:41,981] Trial 1169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:42,136] Trial 1170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:42,264] Trial 1171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:42,543] Trial 1172 finished with value: 15.769020643737884 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42016852835009605, 'reg_lambda': 0.5545161181198827, 'reg_alpha': 0.15752639976885974, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9901736548332668, 'colsample_bynode': 0.9651728424478945, 'colsample_bytree': 0.9669656283254038, 'colsample_bylevel': 0.976913423801193}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:42,681] Trial 1173 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:42,781] Trial 1174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:42,884] Trial 1175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,197] Trial 1176 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,299] Trial 1177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,401] Trial 1178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,502] Trial 1179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,633] Trial 1180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,737] Trial 1181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,839] Trial 1182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:43,949] Trial 1183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,068] Trial 1184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,180] Trial 1185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,289] Trial 1186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,402] Trial 1187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,510] Trial 1188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,613] Trial 1189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:44,757] Trial 1190 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:44,992] Trial 1191 finished with value: 15.783162431545264 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4340813431677893, 'reg_lambda': 1.1004037119512813, 'reg_alpha': 0.0786456112146589, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9880754709461828, 'colsample_bynode': 0.9428860454522896, 'colsample_bytree': 0.9545912084264986, 'colsample_bylevel': 0.9952913326642119}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:45,178] Trial 1192 finished with value: 15.52826851149705 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4328936088505701, 'reg_lambda': 1.507931430932006, 'reg_alpha': 0.1277820042281342, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9593454792468173, 'colsample_bynode': 0.9460315377548006, 'colsample_bytree': 0.9328187242677075, 'colsample_bylevel': 0.9998791081603781}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:45,360] Trial 1193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:45,484] Trial 1194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:45,588] Trial 1195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:45,692] Trial 1196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:45,796] Trial 1197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:45,900] Trial 1198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:46,008] Trial 1199 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:46,114] Trial 1200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:46,235] Trial 1201 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:46,372] Trial 1202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:46,497] Trial 1203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:46,705] Trial 1204 finished with value: 15.944091820190154 and parameters: {'tree_method': 'hist', 'learning_rate': 0.44939801216761327, 'reg_lambda': 1.5551734626045361, 'reg_alpha': 0.14750219744374413, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9681494130994943, 'colsample_bynode': 0.9425195923083042, 'colsample_bytree': 0.9112635689927792, 'colsample_bylevel': 0.992397638511146}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:46,870] Trial 1205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:46,990] Trial 1206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:47,096] Trial 1207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:47,197] Trial 1208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:47,358] Trial 1209 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:47,474] Trial 1210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:47,695] Trial 1211 finished with value: 15.862755974471677 and parameters: {'tree_method': 'hist', 'learning_rate': 0.44659290155988357, 'reg_lambda': 2.705599939522428, 'reg_alpha': 0.13426028467545123, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9724123555822279, 'colsample_bynode': 0.9485922657689214, 'colsample_bytree': 0.944057823237107, 'colsample_bylevel': 0.9783214769491237}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:47,806] Trial 1212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:47,996] Trial 1213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,121] Trial 1214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,233] Trial 1215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,361] Trial 1216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,462] Trial 1217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,574] Trial 1218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,680] Trial 1219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,782] Trial 1220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:48,886] Trial 1221 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:49,016] Trial 1222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,131] Trial 1223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,238] Trial 1224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,342] Trial 1225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,462] Trial 1226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,566] Trial 1227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,679] Trial 1228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:49,923] Trial 1229 finished with value: 15.817337603011941 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4344145998487693, 'reg_lambda': 2.333481582456222, 'reg_alpha': 0.09441192364585665, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9735087939277557, 'colsample_bynode': 0.9561156682266277, 'colsample_bytree': 0.6267356762313161, 'colsample_bylevel': 0.9724991930295076}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:50,026] Trial 1230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:50,131] Trial 1231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:50,236] Trial 1232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:50,355] Trial 1233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,064] Trial 1234 finished with value: 16.107454305548853 and parameters: {'tree_method': 'hist', 'learning_rate': 0.44084292459742785, 'reg_lambda': 1.2932635316354104, 'reg_alpha': 0.0670941009237359, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9632720127509612, 'colsample_bynode': 0.9881858873395418, 'colsample_bytree': 0.9646619597634312, 'colsample_bylevel': 0.99712969807996}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:51,182] Trial 1235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,284] Trial 1236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,387] Trial 1237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,544] Trial 1238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,653] Trial 1239 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:51,757] Trial 1240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,874] Trial 1241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:51,987] Trial 1242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:52,100] Trial 1243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:52,272] Trial 1244 finished with value: 15.57685923370059 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4667230065901293, 'reg_lambda': 0.8072500943745664, 'reg_alpha': 0.0010067859655261157, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.9917605890779715, 'colsample_bynode': 0.9751214099017892, 'colsample_bytree': 0.9893275856256633, 'colsample_bylevel': 0.9874672180353552}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:52,433] Trial 1245 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:06:52,542] Trial 1246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:52,746] Trial 1247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:52,857] Trial 1248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:52,962] Trial 1249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,066] Trial 1250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,180] Trial 1251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,282] Trial 1252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,383] Trial 1253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,491] Trial 1254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,597] Trial 1255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,714] Trial 1256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,819] Trial 1257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:53,925] Trial 1258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,034] Trial 1259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,159] Trial 1260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,263] Trial 1261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,367] Trial 1262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,484] Trial 1263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,590] Trial 1264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,722] Trial 1265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,842] Trial 1266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:54,949] Trial 1267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,056] Trial 1268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,183] Trial 1269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,290] Trial 1270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,395] Trial 1271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,544] Trial 1272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,676] Trial 1273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,780] Trial 1274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:55,941] Trial 1275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,057] Trial 1276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,172] Trial 1277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,278] Trial 1278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,387] Trial 1279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,497] Trial 1280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,624] Trial 1281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,730] Trial 1282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:56,842] Trial 1283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,149] Trial 1284 finished with value: 16.126697730551175 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48744257064087654, 'reg_lambda': 0.558606831083259, 'reg_alpha': 0.25288401930623056, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.9825791121649246, 'colsample_bynode': 0.9590821834192654, 'colsample_bytree': 0.9652336805582448, 'colsample_bylevel': 0.9995663794595215}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:57,255] Trial 1285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,386] Trial 1286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,493] Trial 1287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,606] Trial 1288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,719] Trial 1289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,835] Trial 1290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:57,946] Trial 1291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,055] Trial 1292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,306] Trial 1293 finished with value: 16.066932601610784 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4113937789878032, 'reg_lambda': 0.2649195787296699, 'reg_alpha': 0.0014275407347949425, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9606183892972658, 'colsample_bynode': 0.9794164871032505, 'colsample_bytree': 0.9987435745270629, 'colsample_bylevel': 0.8740977601169507}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:06:58,419] Trial 1294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,523] Trial 1295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,643] Trial 1296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,748] Trial 1297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,862] Trial 1298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:58,988] Trial 1299 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:06:59,097] Trial 1300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,204] Trial 1301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,308] Trial 1302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,415] Trial 1303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,529] Trial 1304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,638] Trial 1305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,751] Trial 1306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,857] Trial 1307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:06:59,969] Trial 1308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,079] Trial 1309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,187] Trial 1310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,309] Trial 1311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,422] Trial 1312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,564] Trial 1313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,710] Trial 1314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:00,863] Trial 1315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,003] Trial 1316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,110] Trial 1317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,216] Trial 1318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,323] Trial 1319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,434] Trial 1320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,546] Trial 1321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,653] Trial 1322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,761] Trial 1323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,874] Trial 1324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:01,993] Trial 1325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,116] Trial 1326 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:07:02,228] Trial 1327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,337] Trial 1328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,458] Trial 1329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,570] Trial 1330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,681] Trial 1331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,801] Trial 1332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:02,915] Trial 1333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,025] Trial 1334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,137] Trial 1335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,272] Trial 1336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,394] Trial 1337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,507] Trial 1338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,619] Trial 1339 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:03,735] Trial 1340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:03,842] Trial 1341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,018] Trial 1342 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:04,181] Trial 1343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,296] Trial 1344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,413] Trial 1345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,532] Trial 1346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,647] Trial 1347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,761] Trial 1348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:04,875] Trial 1349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,015] Trial 1350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,133] Trial 1351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,245] Trial 1352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,357] Trial 1353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,467] Trial 1354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,579] Trial 1355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,746] Trial 1356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,876] Trial 1357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:05,999] Trial 1358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,111] Trial 1359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,224] Trial 1360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,340] Trial 1361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,449] Trial 1362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,593] Trial 1363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,707] Trial 1364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:06,986] Trial 1365 finished with value: 15.463232655738368 and parameters: {'tree_method': 'hist', 'learning_rate': 0.45448507746288164, 'reg_lambda': 0.4954919832315426, 'reg_alpha': 0.002712764180033013, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9817756232193214, 'colsample_bynode': 0.5209510445979475, 'colsample_bytree': 0.9373573454709399, 'colsample_bylevel': 0.671486558077798}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:07,098] Trial 1366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:07,210] Trial 1367 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:07,327] Trial 1368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:07,452] Trial 1369 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:07,574] Trial 1370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:07,687] Trial 1371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:07,804] Trial 1372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:07,911] Trial 1373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,028] Trial 1374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,143] Trial 1375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,267] Trial 1376 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:08,379] Trial 1377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,496] Trial 1378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,608] Trial 1379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,721] Trial 1380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:08,885] Trial 1381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,011] Trial 1382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,124] Trial 1383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,238] Trial 1384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,348] Trial 1385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,461] Trial 1386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,574] Trial 1387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,690] Trial 1388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,807] Trial 1389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:09,927] Trial 1390 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:10,148] Trial 1391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:10,262] Trial 1392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:10,379] Trial 1393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:10,492] Trial 1394 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:10,622] Trial 1395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:10,744] Trial 1396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:10,868] Trial 1397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,010] Trial 1398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,188] Trial 1399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,312] Trial 1400 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,443] Trial 1401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,572] Trial 1402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,697] Trial 1403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,813] Trial 1404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:11,927] Trial 1405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,084] Trial 1406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,205] Trial 1407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,339] Trial 1408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,460] Trial 1409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,611] Trial 1410 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:07:12,729] Trial 1411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,843] Trial 1412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:12,984] Trial 1413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,119] Trial 1414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,264] Trial 1415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,381] Trial 1416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,508] Trial 1417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,639] Trial 1418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,836] Trial 1419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:13,985] Trial 1420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,111] Trial 1421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,228] Trial 1422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,343] Trial 1423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,464] Trial 1424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,586] Trial 1425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,706] Trial 1426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,831] Trial 1427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:14,960] Trial 1428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,084] Trial 1429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,211] Trial 1430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,347] Trial 1431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,479] Trial 1432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,624] Trial 1433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,740] Trial 1434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:15,938] Trial 1435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,082] Trial 1436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,200] Trial 1437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,321] Trial 1438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,439] Trial 1439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,666] Trial 1440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,801] Trial 1441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:16,929] Trial 1442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,043] Trial 1443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,193] Trial 1444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,329] Trial 1445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,447] Trial 1446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,581] Trial 1447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,719] Trial 1448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,842] Trial 1449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:17,958] Trial 1450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,076] Trial 1451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,207] Trial 1452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,334] Trial 1453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,447] Trial 1454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,560] Trial 1455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,686] Trial 1456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,808] Trial 1457 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:18,922] Trial 1458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,040] Trial 1459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,157] Trial 1460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,287] Trial 1461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,411] Trial 1462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,526] Trial 1463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,642] Trial 1464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,759] Trial 1465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,875] Trial 1466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:19,995] Trial 1467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:20,121] Trial 1468 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:20,239] Trial 1469 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:20,358] Trial 1470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:20,488] Trial 1471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:20,681] Trial 1472 finished with value: 15.852989114484366 and parameters: {'tree_method': 'hist', 'learning_rate': 0.46142971404729216, 'reg_lambda': 0.7080023987646225, 'reg_alpha': 0.0031915436442060095, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9664501260755175, 'colsample_bynode': 0.5292615752368888, 'colsample_bytree': 0.9733971364286138, 'colsample_bylevel': 0.6923579116743998}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:20,834] Trial 1473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:20,970] Trial 1474 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:21,086] Trial 1475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:21,301] Trial 1476 finished with value: 15.895700923156012 and parameters: {'tree_method': 'hist', 'learning_rate': 0.429763746512558, 'reg_lambda': 0.1464664224240609, 'reg_alpha': 0.18199605161576737, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9736831688503398, 'colsample_bynode': 0.9687456251996482, 'colsample_bytree': 0.7138210369712813, 'colsample_bylevel': 0.9755421124617351}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:21,455] Trial 1477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:21,581] Trial 1478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:21,701] Trial 1479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:21,838] Trial 1480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:21,982] Trial 1481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,110] Trial 1482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,235] Trial 1483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,390] Trial 1484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,509] Trial 1485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,654] Trial 1486 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,775] Trial 1487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:22,950] Trial 1488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,198] Trial 1489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,359] Trial 1490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,487] Trial 1491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,604] Trial 1492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,751] Trial 1493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,864] Trial 1494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:23,980] Trial 1495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,099] Trial 1496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,328] Trial 1497 finished with value: 16.118843015656285 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4360345369788597, 'reg_lambda': 0.5216054836355922, 'reg_alpha': 0.2578563940502316, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9709581206907705, 'colsample_bynode': 0.5843791152056436, 'colsample_bytree': 0.945402226471459, 'colsample_bylevel': 0.6650326165655868}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:24,447] Trial 1498 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,564] Trial 1499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,696] Trial 1500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,816] Trial 1501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:24,971] Trial 1502 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,098] Trial 1503 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,221] Trial 1504 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,343] Trial 1505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,465] Trial 1506 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,687] Trial 1507 finished with value: 15.9428480909722 and parameters: {'tree_method': 'hist', 'learning_rate': 0.45190936872345355, 'reg_lambda': 0.5074999738956542, 'reg_alpha': 0.002055009136926539, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9780575887535119, 'colsample_bynode': 0.5354568066923375, 'colsample_bytree': 0.9810252671106792, 'colsample_bylevel': 0.6869770377205148}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:25,805] Trial 1508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:25,943] Trial 1509 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,076] Trial 1510 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,219] Trial 1511 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,349] Trial 1512 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,466] Trial 1513 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,589] Trial 1514 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:26,866] Trial 1515 finished with value: 15.947929452622727 and parameters: {'tree_method': 'hist', 'learning_rate': 0.43957520177192505, 'reg_lambda': 0.25638245140807125, 'reg_alpha': 0.001607297888017904, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9999173724563225, 'colsample_bynode': 0.9912351662619979, 'colsample_bytree': 0.965982745179831, 'colsample_bylevel': 0.9998134159294706}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:26,986] Trial 1516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:27,136] Trial 1517 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:27,665] Trial 1518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:27,833] Trial 1519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,072] Trial 1520 finished with value: 15.310709490002424 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48589245272590764, 'reg_lambda': 0.3179508336277128, 'reg_alpha': 0.0022499241653249884, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9668627169169206, 'colsample_bynode': 0.5711829876651574, 'colsample_bytree': 0.9446766297223226, 'colsample_bylevel': 0.8611250453284577}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:28,189] Trial 1521 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,320] Trial 1522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,489] Trial 1523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,612] Trial 1524 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,729] Trial 1525 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,846] Trial 1526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:28,964] Trial 1527 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,079] Trial 1528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,198] Trial 1529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,316] Trial 1530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,474] Trial 1531 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,592] Trial 1532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,712] Trial 1533 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:29,840] Trial 1534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,040] Trial 1535 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,164] Trial 1536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,285] Trial 1537 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,403] Trial 1538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,521] Trial 1539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,638] Trial 1540 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,774] Trial 1541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:30,902] Trial 1542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,121] Trial 1543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,274] Trial 1544 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,396] Trial 1545 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,521] Trial 1546 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,641] Trial 1547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:31,824] Trial 1548 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,012] Trial 1549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,133] Trial 1550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,303] Trial 1551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,423] Trial 1552 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,543] Trial 1553 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,668] Trial 1554 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:32,830] Trial 1555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,013] Trial 1556 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,133] Trial 1557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,280] Trial 1558 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:33,414] Trial 1559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,556] Trial 1560 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,697] Trial 1561 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:33,825] Trial 1562 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,029] Trial 1563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,152] Trial 1564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,331] Trial 1565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,463] Trial 1566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,607] Trial 1567 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:34,880] Trial 1568 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,006] Trial 1569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,136] Trial 1570 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,266] Trial 1571 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,388] Trial 1572 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,511] Trial 1573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,632] Trial 1574 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,752] Trial 1575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:35,879] Trial 1576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,000] Trial 1577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,140] Trial 1578 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,311] Trial 1579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,444] Trial 1580 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,567] Trial 1581 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,692] Trial 1582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,823] Trial 1583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:36,946] Trial 1584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,086] Trial 1585 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:37,223] Trial 1586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,357] Trial 1587 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,485] Trial 1588 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,611] Trial 1589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,741] Trial 1590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:37,888] Trial 1591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:38,012] Trial 1592 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:38,162] Trial 1593 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:38,299] Trial 1594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:38,445] Trial 1595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:38,691] Trial 1596 finished with value: 15.926304298538497 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3974219668482142, 'reg_lambda': 0.4767591682607357, 'reg_alpha': 0.004171877883715278, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9661801304970964, 'colsample_bynode': 0.5324265595261584, 'colsample_bytree': 0.6928724541541335, 'colsample_bylevel': 0.6487031501562107}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:38,816] Trial 1597 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,035] Trial 1598 finished with value: 15.739915368229983 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4054831274316253, 'reg_lambda': 0.5983695158400277, 'reg_alpha': 0.002866319487315166, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9998096541825379, 'colsample_bynode': 0.5653600606577451, 'colsample_bytree': 0.9406561641158032, 'colsample_bylevel': 0.6670062046213167}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:39,159] Trial 1599 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,280] Trial 1600 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,415] Trial 1601 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,546] Trial 1602 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,670] Trial 1603 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,793] Trial 1604 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:39,921] Trial 1605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,048] Trial 1606 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,223] Trial 1607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,356] Trial 1608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,481] Trial 1609 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,609] Trial 1610 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,737] Trial 1611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,865] Trial 1612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:40,990] Trial 1613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,134] Trial 1614 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,271] Trial 1615 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,410] Trial 1616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,620] Trial 1617 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,758] Trial 1618 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:41,890] Trial 1619 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,016] Trial 1620 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,148] Trial 1621 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,299] Trial 1622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,441] Trial 1623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,596] Trial 1624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,727] Trial 1625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:42,876] Trial 1626 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,023] Trial 1627 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,155] Trial 1628 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,297] Trial 1629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,440] Trial 1630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,598] Trial 1631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,742] Trial 1632 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:43,876] Trial 1633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:44,025] Trial 1634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:44,159] Trial 1635 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:44,471] Trial 1636 finished with value: 15.83746060994082 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4079355983731531, 'reg_lambda': 0.570665296952045, 'reg_alpha': 0.007573504003329812, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9994723100597843, 'colsample_bynode': 0.5584194430906321, 'colsample_bytree': 0.9548707006607859, 'colsample_bylevel': 0.6701932960704037}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:44,596] Trial 1637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:44,727] Trial 1638 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:44,856] Trial 1639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,003] Trial 1640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,131] Trial 1641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,261] Trial 1642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,394] Trial 1643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,532] Trial 1644 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,660] Trial 1645 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,834] Trial 1646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:45,973] Trial 1647 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,102] Trial 1648 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,232] Trial 1649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,364] Trial 1650 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,549] Trial 1651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,678] Trial 1652 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,819] Trial 1653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:46,953] Trial 1654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:47,079] Trial 1655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:47,209] Trial 1656 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:47,377] Trial 1657 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:47,738] Trial 1658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:47,876] Trial 1659 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,025] Trial 1660 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,155] Trial 1661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,283] Trial 1662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,427] Trial 1663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,710] Trial 1664 finished with value: 15.774979300896758 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4821968059527408, 'reg_lambda': 0.6682501552459372, 'reg_alpha': 0.0026113997484742313, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9752672902116688, 'colsample_bynode': 0.5456465738099473, 'colsample_bytree': 0.6995644264433077, 'colsample_bylevel': 0.6674515747946707}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:48,838] Trial 1665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:48,967] Trial 1666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,103] Trial 1667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,243] Trial 1668 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,406] Trial 1669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,543] Trial 1670 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,671] Trial 1671 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:49,804] Trial 1672 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:50,037] Trial 1673 finished with value: 15.783744163205025 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4898386704706039, 'reg_lambda': 0.34859635613766493, 'reg_alpha': 0.0014368296307135518, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9710397414259604, 'colsample_bynode': 0.5596182088955237, 'colsample_bytree': 0.9193309958085426, 'colsample_bylevel': 0.6622630281291911}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:50,171] Trial 1674 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:50,312] Trial 1675 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:50,458] Trial 1676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:50,596] Trial 1677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:50,744] Trial 1678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:50,876] Trial 1679 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,031] Trial 1680 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,168] Trial 1681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,299] Trial 1682 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,438] Trial 1683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,569] Trial 1684 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,696] Trial 1685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,830] Trial 1686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:51,961] Trial 1687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:52,115] Trial 1688 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:52,254] Trial 1689 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:52,383] Trial 1690 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:52,602] Trial 1691 finished with value: 15.809303422780967 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47394896273846004, 'reg_lambda': 1.1521378486424978, 'reg_alpha': 0.0012328798698634906, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9679159245283306, 'colsample_bynode': 0.5287534361733894, 'colsample_bytree': 0.9515521808669319, 'colsample_bylevel': 0.6962804910676182}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:52,742] Trial 1692 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:52,880] Trial 1693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:53,111] Trial 1694 finished with value: 15.743163556803157 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39835988115132365, 'reg_lambda': 0.9170275984032897, 'reg_alpha': 0.0010006999915499035, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9999753187939858, 'colsample_bynode': 0.5379963376928929, 'colsample_bytree': 0.9308608468632772, 'colsample_bylevel': 0.6747347750958987}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:53,247] Trial 1695 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:53,523] Trial 1696 finished with value: 15.83793583078601 and parameters: {'tree_method': 'hist', 'learning_rate': 0.39792001051534387, 'reg_lambda': 0.6840621567396474, 'reg_alpha': 0.0025994627106788576, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.998464378983688, 'colsample_bynode': 0.5347879902742206, 'colsample_bytree': 0.9292242171784375, 'colsample_bylevel': 0.6900447342252166}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:53,698] Trial 1697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:53,835] Trial 1698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:53,990] Trial 1699 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:54,251] Trial 1700 finished with value: 15.597752256959764 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3888421008043168, 'reg_lambda': 0.5751994613146816, 'reg_alpha': 0.0014755883024561052, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.999556920149108, 'colsample_bynode': 0.5375451989754572, 'colsample_bytree': 0.9361774825541417, 'colsample_bylevel': 0.6717888952300622}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:54,384] Trial 1701 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:54,536] Trial 1702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:54,682] Trial 1703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:54,834] Trial 1704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:54,989] Trial 1705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:55,245] Trial 1706 finished with value: 15.7402230651402 and parameters: {'tree_method': 'hist', 'learning_rate': 0.3761795599078546, 'reg_lambda': 0.5596808931561454, 'reg_alpha': 0.0017461749736755548, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9999799444200984, 'colsample_bynode': 0.5254250869792446, 'colsample_bytree': 0.9439239954797298, 'colsample_bylevel': 0.6584942836724851}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:07:55,386] Trial 1707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:55,532] Trial 1708 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:55,666] Trial 1709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:55,804] Trial 1710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:55,940] Trial 1711 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:56,070] Trial 1712 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:56,203] Trial 1713 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:56,342] Trial 1714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:56,472] Trial 1715 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:56,627] Trial 1716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:56,778] Trial 1717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:56,937] Trial 1718 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,072] Trial 1719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,209] Trial 1720 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,342] Trial 1721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,479] Trial 1722 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,626] Trial 1723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,757] Trial 1724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:57,893] Trial 1725 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,066] Trial 1726 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,211] Trial 1727 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,363] Trial 1728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,506] Trial 1729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,659] Trial 1730 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:07:58,798] Trial 1731 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:58,934] Trial 1732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,083] Trial 1733 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,223] Trial 1734 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,359] Trial 1735 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,496] Trial 1736 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,635] Trial 1737 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,772] Trial 1738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:07:59,914] Trial 1739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,052] Trial 1740 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,195] Trial 1741 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,334] Trial 1742 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,475] Trial 1743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,614] Trial 1744 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,751] Trial 1745 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:00,889] Trial 1746 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:01,039] Trial 1747 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:01,189] Trial 1748 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:01,339] Trial 1749 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:01,504] Trial 1750 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:01,910] Trial 1751 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:02,084] Trial 1752 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:02,796] Trial 1753 finished with value: 15.88148266610383 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4946821271463674, 'reg_lambda': 0.5121684171753391, 'reg_alpha': 0.001324572801381579, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9768306842182344, 'colsample_bynode': 0.5297278368135003, 'colsample_bytree': 0.9495876660595206, 'colsample_bylevel': 0.6747288275088666}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:03,187] Trial 1754 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:03,336] Trial 1755 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:03,477] Trial 1756 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:03,638] Trial 1757 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:03,784] Trial 1758 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:03,921] Trial 1759 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,057] Trial 1760 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,197] Trial 1761 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,338] Trial 1762 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,479] Trial 1763 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,626] Trial 1764 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,765] Trial 1765 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:04,914] Trial 1766 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,057] Trial 1767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,210] Trial 1768 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,376] Trial 1769 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,521] Trial 1770 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,682] Trial 1771 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,824] Trial 1772 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:05,962] Trial 1773 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,100] Trial 1774 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,239] Trial 1775 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,377] Trial 1776 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,517] Trial 1777 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,662] Trial 1778 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,850] Trial 1779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:06,996] Trial 1780 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,131] Trial 1781 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,271] Trial 1782 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,431] Trial 1783 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,568] Trial 1784 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,709] Trial 1785 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,853] Trial 1786 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:07,998] Trial 1787 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,137] Trial 1788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,298] Trial 1789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,434] Trial 1790 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,579] Trial 1791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,721] Trial 1792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,858] Trial 1793 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:08,991] Trial 1794 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,127] Trial 1795 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,266] Trial 1796 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,419] Trial 1797 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,558] Trial 1798 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,698] Trial 1799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,836] Trial 1800 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:09,974] Trial 1801 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,111] Trial 1802 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,254] Trial 1803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,393] Trial 1804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,535] Trial 1805 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,702] Trial 1806 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:10,959] Trial 1807 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:11,113] Trial 1808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:11,265] Trial 1809 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:11,417] Trial 1810 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:11,678] Trial 1811 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:11,829] Trial 1812 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:11,983] Trial 1813 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,130] Trial 1814 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,348] Trial 1815 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,489] Trial 1816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,630] Trial 1817 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,783] Trial 1818 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:12,928] Trial 1819 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:13,146] Trial 1820 finished with value: 15.720031802943659 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48002891428968164, 'reg_lambda': 0.6105103937007803, 'reg_alpha': 0.009580650736076012, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9630241911721714, 'colsample_bynode': 0.5240979521487423, 'colsample_bytree': 0.928638566141284, 'colsample_bylevel': 0.6432022906887831}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:13,291] Trial 1821 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:13,426] Trial 1822 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:13,579] Trial 1823 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:13,735] Trial 1824 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:13,871] Trial 1825 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:14,011] Trial 1826 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:14,149] Trial 1827 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:14,286] Trial 1828 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:14,460] Trial 1829 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:14,664] Trial 1830 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:14,892] Trial 1831 finished with value: 15.49957316901662 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48970952764636627, 'reg_lambda': 0.4579175547512406, 'reg_alpha': 0.015931144579901482, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9549637357373205, 'colsample_bynode': 0.5315252727625254, 'colsample_bytree': 0.9290371681635525, 'colsample_bylevel': 0.6304631703226607}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:15,029] Trial 1832 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,171] Trial 1833 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,315] Trial 1834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,458] Trial 1835 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,602] Trial 1836 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,751] Trial 1837 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:15,890] Trial 1838 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,048] Trial 1839 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,212] Trial 1840 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,368] Trial 1841 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,532] Trial 1842 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,680] Trial 1843 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:16,833] Trial 1844 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,004] Trial 1845 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,276] Trial 1846 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,444] Trial 1847 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,595] Trial 1848 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,751] Trial 1849 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:17,907] Trial 1850 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:18,049] Trial 1851 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:18,190] Trial 1852 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:18,365] Trial 1853 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:18,510] Trial 1854 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:18,786] Trial 1855 finished with value: 15.857176715720628 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4846027550524708, 'reg_lambda': 0.7060678815685745, 'reg_alpha': 0.01917110633210694, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9647377809024065, 'colsample_bynode': 0.5323358122847868, 'colsample_bytree': 0.9366265219361969, 'colsample_bylevel': 0.6465563011001858}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:18,973] Trial 1856 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,118] Trial 1857 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,259] Trial 1858 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,404] Trial 1859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,554] Trial 1860 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:08:19,695] Trial 1861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,849] Trial 1862 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:19,989] Trial 1863 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:20,208] Trial 1864 finished with value: 15.856533034454118 and parameters: {'tree_method': 'hist', 'learning_rate': 0.469239217810435, 'reg_lambda': 0.570823646340039, 'reg_alpha': 0.024634089219919865, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9493371134823294, 'colsample_bynode': 0.5276156414757476, 'colsample_bytree': 0.9241411713718535, 'colsample_bylevel': 0.6268115666893527}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:20,347] Trial 1865 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:20,486] Trial 1866 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:20,628] Trial 1867 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:20,777] Trial 1868 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:20,922] Trial 1869 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:21,062] Trial 1870 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:21,320] Trial 1871 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:21,537] Trial 1872 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:21,704] Trial 1873 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:21,871] Trial 1874 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,022] Trial 1875 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,164] Trial 1876 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,309] Trial 1877 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,453] Trial 1878 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,596] Trial 1879 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,750] Trial 1880 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:22,900] Trial 1881 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:23,045] Trial 1882 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:23,195] Trial 1883 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:23,354] Trial 1884 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:23,581] Trial 1885 finished with value: 15.905046189073598 and parameters: {'tree_method': 'hist', 'learning_rate': 0.455058766093722, 'reg_lambda': 0.38426211747359496, 'reg_alpha': 0.00847769683419508, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.963496532315774, 'colsample_bynode': 0.5325380709857652, 'colsample_bytree': 0.9437954837125443, 'colsample_bylevel': 0.6746481932046829}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:23,731] Trial 1886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:23,876] Trial 1887 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,026] Trial 1888 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,168] Trial 1889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,319] Trial 1890 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,465] Trial 1891 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,609] Trial 1892 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,751] Trial 1893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:24,969] Trial 1894 finished with value: 15.829289313375343 and parameters: {'tree_method': 'hist', 'learning_rate': 0.47848150152476526, 'reg_lambda': 1.1283247901504594, 'reg_alpha': 0.46313094421302425, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9774542718122622, 'colsample_bynode': 0.5233480392630765, 'colsample_bytree': 0.9273303833602301, 'colsample_bylevel': 0.684277495486661}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:25,118] Trial 1895 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,259] Trial 1896 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,402] Trial 1897 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,541] Trial 1898 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,683] Trial 1899 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,825] Trial 1900 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:25,974] Trial 1901 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:26,139] Trial 1902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:26,280] Trial 1903 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:26,423] Trial 1904 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:26,640] Trial 1905 finished with value: 15.820842355417188 and parameters: {'tree_method': 'hist', 'learning_rate': 0.45665072841920085, 'reg_lambda': 0.6276369235688358, 'reg_alpha': 0.0010076562742449534, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9801590350862003, 'colsample_bynode': 0.5448815320277939, 'colsample_bytree': 0.9512058518386595, 'colsample_bylevel': 0.6751802678654024}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:26,795] Trial 1906 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:26,984] Trial 1907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,168] Trial 1908 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,338] Trial 1909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,484] Trial 1910 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,632] Trial 1911 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,776] Trial 1912 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:27,924] Trial 1913 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,077] Trial 1914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,232] Trial 1915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,393] Trial 1916 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,542] Trial 1917 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,703] Trial 1918 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:28,853] Trial 1919 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,001] Trial 1920 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,147] Trial 1921 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,295] Trial 1922 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:29,442] Trial 1923 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,589] Trial 1924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,740] Trial 1925 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:29,887] Trial 1926 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,033] Trial 1927 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,191] Trial 1928 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,341] Trial 1929 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,490] Trial 1930 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,640] Trial 1931 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,790] Trial 1932 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:30,937] Trial 1933 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,083] Trial 1934 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,233] Trial 1935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,382] Trial 1936 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,531] Trial 1937 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,682] Trial 1938 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,831] Trial 1939 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:31,985] Trial 1940 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,130] Trial 1941 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,300] Trial 1942 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,454] Trial 1943 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,617] Trial 1944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,776] Trial 1945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:32,926] Trial 1946 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,077] Trial 1947 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,226] Trial 1948 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,377] Trial 1949 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,538] Trial 1950 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,704] Trial 1951 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:33,858] Trial 1952 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,008] Trial 1953 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,154] Trial 1954 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,321] Trial 1955 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,470] Trial 1956 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,623] Trial 1957 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,776] Trial 1958 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:34,932] Trial 1959 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,083] Trial 1960 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,231] Trial 1961 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,384] Trial 1962 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,537] Trial 1963 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,702] Trial 1964 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:35,854] Trial 1965 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,009] Trial 1966 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,156] Trial 1967 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,307] Trial 1968 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,463] Trial 1969 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,614] Trial 1970 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:36,766] Trial 1971 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:37,052] Trial 1972 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:37,314] Trial 1973 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:37,485] Trial 1974 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:37,636] Trial 1975 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:37,920] Trial 1976 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:38,305] Trial 1977 finished with value: 15.984107805617196 and parameters: {'tree_method': 'hist', 'learning_rate': 0.49400389470189593, 'reg_lambda': 1.3176840263759062, 'reg_alpha': 0.008276890857905035, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9565531854221737, 'colsample_bynode': 0.7982641309012479, 'colsample_bytree': 0.7044826589077936, 'colsample_bylevel': 0.9002402771494885}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:38,502] Trial 1978 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:38,655] Trial 1979 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:38,811] Trial 1980 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:38,962] Trial 1981 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,115] Trial 1982 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,274] Trial 1983 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,426] Trial 1984 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,582] Trial 1985 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,739] Trial 1986 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:39,895] Trial 1987 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,056] Trial 1988 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,225] Trial 1989 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,375] Trial 1990 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,533] Trial 1991 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,682] Trial 1992 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,834] Trial 1993 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:40,990] Trial 1994 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:41,137] Trial 1995 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:41,366] Trial 1996 finished with value: 16.058397078008582 and parameters: {'tree_method': 'hist', 'learning_rate': 0.48693486959030036, 'reg_lambda': 0.8395490705698183, 'reg_alpha': 0.11630371264020271, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9516941825012978, 'colsample_bynode': 0.5424650727171718, 'colsample_bytree': 0.9145868392815127, 'colsample_bylevel': 0.653651691136017}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:41,514] Trial 1997 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:41,665] Trial 1998 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:41,815] Trial 1999 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:41,966] Trial 2000 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,117] Trial 2001 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,267] Trial 2002 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,415] Trial 2003 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,583] Trial 2004 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,730] Trial 2005 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:42,876] Trial 2006 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:43,032] Trial 2007 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:43,198] Trial 2008 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:43,355] Trial 2009 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:43,552] Trial 2010 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:43,708] Trial 2011 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:43,873] Trial 2012 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,033] Trial 2013 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,197] Trial 2014 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,366] Trial 2015 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,531] Trial 2016 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,713] Trial 2017 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:44,874] Trial 2018 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,030] Trial 2019 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,186] Trial 2020 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,335] Trial 2021 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,483] Trial 2022 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,635] Trial 2023 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,787] Trial 2024 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:45,935] Trial 2025 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,085] Trial 2026 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,229] Trial 2027 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,376] Trial 2028 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,519] Trial 2029 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,669] Trial 2030 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,814] Trial 2031 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:46,961] Trial 2032 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,109] Trial 2033 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,252] Trial 2034 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,393] Trial 2035 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,587] Trial 2036 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,731] Trial 2037 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:47,889] Trial 2038 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,037] Trial 2039 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,181] Trial 2040 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,327] Trial 2041 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,471] Trial 2042 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,645] Trial 2043 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:48,827] Trial 2044 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,000] Trial 2045 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,154] Trial 2046 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,309] Trial 2047 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,461] Trial 2048 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,611] Trial 2049 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,758] Trial 2050 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:49,908] Trial 2051 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:50,065] Trial 2052 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,218] Trial 2053 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,371] Trial 2054 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,520] Trial 2055 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,667] Trial 2056 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,829] Trial 2057 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:50,977] Trial 2058 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:51,123] Trial 2059 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:51,271] Trial 2060 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:51,419] Trial 2061 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:51,862] Trial 2062 finished with value: 15.87983092625968 and parameters: {'tree_method': 'approx', 'learning_rate': 0.4532195453741903, 'reg_lambda': 0.4595811881564673, 'reg_alpha': 0.001378535345390568, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9650713602556097, 'colsample_bynode': 0.5171114614502056, 'colsample_bytree': 0.9287219140120156, 'colsample_bylevel': 0.6762049767466696}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:52,029] Trial 2063 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:52,283] Trial 2064 finished with value: 15.467979781179665 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4401902854798942, 'reg_lambda': 0.32579714975161234, 'reg_alpha': 0.008721901430317829, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9483065902496073, 'colsample_bynode': 0.5372120839034964, 'colsample_bytree': 0.7732109344083742, 'colsample_bylevel': 0.9643648190706968}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:08:52,434] Trial 2065 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:52,587] Trial 2066 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:52,737] Trial 2067 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:52,906] Trial 2068 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:53,061] Trial 2069 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:53,223] Trial 2070 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:53,376] Trial 2071 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:53,526] Trial 2072 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:53,704] Trial 2073 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:53,868] Trial 2074 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:08:54,035] Trial 2075 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,191] Trial 2076 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,353] Trial 2077 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,499] Trial 2078 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,646] Trial 2079 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,790] Trial 2080 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:54,944] Trial 2081 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,093] Trial 2082 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,242] Trial 2083 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,394] Trial 2084 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,547] Trial 2085 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,694] Trial 2086 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,838] Trial 2087 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:55,984] Trial 2088 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,143] Trial 2089 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,288] Trial 2090 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,436] Trial 2091 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,585] Trial 2092 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,741] Trial 2093 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:56,904] Trial 2094 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:57,081] Trial 2095 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:57,237] Trial 2096 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:57,398] Trial 2097 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:57,554] Trial 2098 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:57,748] Trial 2099 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:58,016] Trial 2100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:58,206] Trial 2101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:58,364] Trial 2102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:58,515] Trial 2103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:58,828] Trial 2104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:59,050] Trial 2105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:59,203] Trial 2106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:59,364] Trial 2107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:59,735] Trial 2108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:08:59,907] Trial 2109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:00,070] Trial 2110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:00,238] Trial 2111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:00,412] Trial 2112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:00,582] Trial 2113 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:00,739] Trial 2114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:00,896] Trial 2115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,057] Trial 2116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,237] Trial 2117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,396] Trial 2118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,568] Trial 2119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,734] Trial 2120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:01,897] Trial 2121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,056] Trial 2122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,222] Trial 2123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,386] Trial 2124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,544] Trial 2125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,703] Trial 2126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:02,866] Trial 2127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,033] Trial 2128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,209] Trial 2129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,371] Trial 2130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,533] Trial 2131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,687] Trial 2132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:03,862] Trial 2133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,036] Trial 2134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,204] Trial 2135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,376] Trial 2136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,544] Trial 2137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,705] Trial 2138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:04,893] Trial 2139 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,069] Trial 2140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,267] Trial 2141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,430] Trial 2142 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,590] Trial 2143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,748] Trial 2144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:05,906] Trial 2145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:06,065] Trial 2146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:06,227] Trial 2147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:06,386] Trial 2148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:06,549] Trial 2149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:06,712] Trial 2150 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:06,870] Trial 2151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:07,034] Trial 2152 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:07,199] Trial 2153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:07,374] Trial 2154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:07,532] Trial 2155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:07,694] Trial 2156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:07,891] Trial 2157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,047] Trial 2158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,201] Trial 2159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,368] Trial 2160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,528] Trial 2161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,690] Trial 2162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:08,981] Trial 2163 finished with value: 15.884300470777713 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4643609561593272, 'reg_lambda': 0.7263374200864632, 'reg_alpha': 0.24639945532052934, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9997941880506902, 'colsample_bynode': 0.5130350731923923, 'colsample_bytree': 0.9565151702079527, 'colsample_bylevel': 0.643736747186286}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:09,138] Trial 2164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:09,301] Trial 2165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:09,473] Trial 2166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:09,642] Trial 2167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:09,807] Trial 2168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:09,970] Trial 2169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,137] Trial 2170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,319] Trial 2171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,493] Trial 2172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,665] Trial 2173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,830] Trial 2174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:10,998] Trial 2175 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:11,163] Trial 2176 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:11,336] Trial 2177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:11,517] Trial 2178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:11,782] Trial 2179 finished with value: 15.451431231712181 and parameters: {'tree_method': 'hist', 'learning_rate': 0.29080380808920636, 'reg_lambda': 0.3215796896445941, 'reg_alpha': 0.019149946591672906, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.97193582707384, 'colsample_bynode': 0.7319571483048649, 'colsample_bytree': 0.7213011725429679, 'colsample_bylevel': 0.6352502739769272}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:11,962] Trial 2180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,136] Trial 2181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,310] Trial 2182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,478] Trial 2183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,651] Trial 2184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,827] Trial 2185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:12,988] Trial 2186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:13,157] Trial 2187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:13,334] Trial 2188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:13,530] Trial 2189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:13,691] Trial 2190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:13,850] Trial 2191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,034] Trial 2192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,203] Trial 2193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,378] Trial 2194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,544] Trial 2195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,777] Trial 2196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:14,948] Trial 2197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,114] Trial 2198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,281] Trial 2199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,450] Trial 2200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,639] Trial 2201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,810] Trial 2202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:15,989] Trial 2203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:16,145] Trial 2204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:16,314] Trial 2205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:16,489] Trial 2206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:16,662] Trial 2207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:16,833] Trial 2208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,003] Trial 2209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,176] Trial 2210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,349] Trial 2211 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,510] Trial 2212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,691] Trial 2213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:17,853] Trial 2214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,065] Trial 2215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,253] Trial 2216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,427] Trial 2217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,593] Trial 2218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,759] Trial 2219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:18,944] Trial 2220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:19,137] Trial 2221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:19,313] Trial 2222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:19,494] Trial 2223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:19,685] Trial 2224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:19,880] Trial 2225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:20,333] Trial 2226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:20,547] Trial 2227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:20,735] Trial 2228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:20,907] Trial 2229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:21,094] Trial 2230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:21,266] Trial 2231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:21,457] Trial 2232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:21,631] Trial 2233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:21,805] Trial 2234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,004] Trial 2235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,197] Trial 2236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,373] Trial 2237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,541] Trial 2238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,728] Trial 2239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:22,901] Trial 2240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,076] Trial 2241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,247] Trial 2242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,444] Trial 2243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,613] Trial 2244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,787] Trial 2245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:23,962] Trial 2246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:24,151] Trial 2247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:24,317] Trial 2248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:24,498] Trial 2249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:24,666] Trial 2250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:24,958] Trial 2251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:25,647] Trial 2252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:26,285] Trial 2253 finished with value: 15.88724009884713 and parameters: {'tree_method': 'hist', 'learning_rate': 0.43254588043438796, 'reg_lambda': 0.16837312392392853, 'reg_alpha': 0.04818115859462274, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9541387434054175, 'colsample_bynode': 0.536938280062913, 'colsample_bytree': 0.7503268559070438, 'colsample_bylevel': 0.9002971321863795}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:26,531] Trial 2254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:26,752] Trial 2255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:26,926] Trial 2256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:27,106] Trial 2257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:27,282] Trial 2258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:27,478] Trial 2259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:27,658] Trial 2260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:27,833] Trial 2261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:28,034] Trial 2262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:28,262] Trial 2263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:28,437] Trial 2264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:28,607] Trial 2265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:28,802] Trial 2266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,040] Trial 2267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,230] Trial 2268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,401] Trial 2269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,593] Trial 2270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,761] Trial 2271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:29,932] Trial 2272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,109] Trial 2273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,284] Trial 2274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,459] Trial 2275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,634] Trial 2276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,805] Trial 2277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:30,974] Trial 2278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:31,144] Trial 2279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:31,312] Trial 2280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:31,487] Trial 2281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:31,665] Trial 2282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:31,861] Trial 2283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,044] Trial 2284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,235] Trial 2285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,408] Trial 2286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,591] Trial 2287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,761] Trial 2288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:32,938] Trial 2289 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:33,110] Trial 2290 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:33,277] Trial 2291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:33,449] Trial 2292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:33,633] Trial 2293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:33,906] Trial 2294 finished with value: 15.783552945802112 and parameters: {'tree_method': 'hist', 'learning_rate': 0.42900126114975856, 'reg_lambda': 0.5947337524347373, 'reg_alpha': 0.0038276653497013335, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9998688525371348, 'colsample_bynode': 0.5422457794993536, 'colsample_bytree': 0.9459274537185162, 'colsample_bylevel': 0.6694580537582071}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:34,069] Trial 2295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:34,255] Trial 2296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:34,435] Trial 2297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:34,608] Trial 2298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:34,786] Trial 2299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:34,967] Trial 2300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:35,139] Trial 2301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:35,309] Trial 2302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:35,487] Trial 2303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:35,679] Trial 2304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:35,861] Trial 2305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,039] Trial 2306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,214] Trial 2307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,388] Trial 2308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,580] Trial 2309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,761] Trial 2310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:36,978] Trial 2311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:37,168] Trial 2312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:37,421] Trial 2313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:37,638] Trial 2314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:37,835] Trial 2315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:38,024] Trial 2316 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:38,218] Trial 2317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:38,486] Trial 2318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:38,671] Trial 2319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:38,847] Trial 2320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,026] Trial 2321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,273] Trial 2322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,445] Trial 2323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,628] Trial 2324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,818] Trial 2325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:39,999] Trial 2326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:40,171] Trial 2327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:40,349] Trial 2328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:40,536] Trial 2329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:40,709] Trial 2330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:41,111] Trial 2331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:41,290] Trial 2332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:41,478] Trial 2333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:41,670] Trial 2334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:41,864] Trial 2335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,033] Trial 2336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,228] Trial 2337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,400] Trial 2338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,583] Trial 2339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,769] Trial 2340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:42,957] Trial 2341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:43,132] Trial 2342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:43,310] Trial 2343 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:43,489] Trial 2344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:43,673] Trial 2345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:43,926] Trial 2346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:44,099] Trial 2347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:44,305] Trial 2348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:44,519] Trial 2349 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:09:44,776] Trial 2350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:44,970] Trial 2351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:45,148] Trial 2352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:45,358] Trial 2353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:45,801] Trial 2354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,054] Trial 2355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,249] Trial 2356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,433] Trial 2357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,611] Trial 2358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,805] Trial 2359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:46,994] Trial 2360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:47,172] Trial 2361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:47,369] Trial 2362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:47,557] Trial 2363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:47,741] Trial 2364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:47,925] Trial 2365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:48,139] Trial 2366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:48,318] Trial 2367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:48,552] Trial 2368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:48,744] Trial 2369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:48,923] Trial 2370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:49,106] Trial 2371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:49,311] Trial 2372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:49,493] Trial 2373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:49,682] Trial 2374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:49,862] Trial 2375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:50,071] Trial 2376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:50,336] Trial 2377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:50,519] Trial 2378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:50,705] Trial 2379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:50,887] Trial 2380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:51,077] Trial 2381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:51,277] Trial 2382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:51,465] Trial 2383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:51,773] Trial 2384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:51,965] Trial 2385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:52,144] Trial 2386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:52,342] Trial 2387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:52,765] Trial 2388 finished with value: 15.78709133701536 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4937169283650375, 'reg_lambda': 0.6721013822087046, 'reg_alpha': 0.004173602561189382, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9833742847257135, 'colsample_bynode': 0.5404144913484933, 'colsample_bytree': 0.9288010454751673, 'colsample_bylevel': 0.6653157028374157}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:52,964] Trial 2389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:53,155] Trial 2390 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:53,461] Trial 2391 finished with value: 15.482869244146588 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4819542307497718, 'reg_lambda': 0.8301818837133759, 'reg_alpha': 0.2307438180334589, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.9736237083144949, 'colsample_bynode': 0.5248256579052165, 'colsample_bytree': 0.9579058741188581, 'colsample_bylevel': 0.6566472744523505}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:53,662] Trial 2392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:53,862] Trial 2393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:54,056] Trial 2394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:54,268] Trial 2395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:54,476] Trial 2396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:54,662] Trial 2397 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-04-02 23:09:54,852] Trial 2398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:55,033] Trial 2399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:55,287] Trial 2400 finished with value: 15.913439101166935 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4875928654158241, 'reg_lambda': 0.7747560007446627, 'reg_alpha': 0.2813776762095493, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9678442928017201, 'colsample_bynode': 0.5415453861459099, 'colsample_bytree': 0.9324917087896772, 'colsample_bylevel': 0.6359181247148853}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:55,477] Trial 2401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:55,678] Trial 2402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:55,862] Trial 2403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:56,071] Trial 2404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:56,414] Trial 2405 finished with value: 15.70779336122881 and parameters: {'tree_method': 'hist', 'learning_rate': 0.49505574567748023, 'reg_lambda': 1.0336244076148715, 'reg_alpha': 0.24568138439633894, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.9569257384166636, 'colsample_bynode': 0.5073852377726366, 'colsample_bytree': 0.9479603105035056, 'colsample_bylevel': 0.6420175356271546}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:09:56,603] Trial 2406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:56,794] Trial 2407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:56,982] Trial 2408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:57,166] Trial 2409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:57,350] Trial 2410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:57,531] Trial 2411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:57,718] Trial 2412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:57,918] Trial 2413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:58,097] Trial 2414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:58,282] Trial 2415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:58,478] Trial 2416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:58,712] Trial 2417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:58,951] Trial 2418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:59,142] Trial 2419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:59,355] Trial 2420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:59,546] Trial 2421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:09:59,735] Trial 2422 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:09:59,924] Trial 2423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:00,109] Trial 2424 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-04-02 23:10:00,297] Trial 2425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:00,473] Trial 2426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:00,667] Trial 2427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:00,843] Trial 2428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,022] Trial 2429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,206] Trial 2430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,389] Trial 2431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,569] Trial 2432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,763] Trial 2433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:01,961] Trial 2434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:02,241] Trial 2435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:02,437] Trial 2436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:02,642] Trial 2437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:02,866] Trial 2438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:03,556] Trial 2439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:04,181] Trial 2440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:04,873] Trial 2441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:05,270] Trial 2442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:05,702] Trial 2443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:06,250] Trial 2444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:06,655] Trial 2445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:07,762] Trial 2446 finished with value: 15.936875008054626 and parameters: {'tree_method': 'hist', 'learning_rate': 0.4964802993775754, 'reg_lambda': 0.8795584215169544, 'reg_alpha': 0.05031085619892493, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9689360571007063, 'colsample_bynode': 0.5389415929698769, 'colsample_bytree': 0.951896509252992, 'colsample_bylevel': 0.6564981165785493}. Best is trial 680 with value: 15.284709147154507.\n",
      "[I 2025-04-02 23:10:08,164] Trial 2447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:08,842] Trial 2448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-04-02 23:10:09,715] Trial 2449 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'hist',\n",
       " 'learning_rate': 0.39863956598229794,\n",
       " 'reg_lambda': 0.92457064534831,\n",
       " 'reg_alpha': 0.0012465313132076418,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 5,\n",
       " 'subsample': 0.9908694324044368,\n",
       " 'colsample_bynode': 0.5695752146388356,\n",
       " 'colsample_bytree': 0.9555642472791113,\n",
       " 'colsample_bylevel': 0.6569817240771461}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "train_time = 60*5 #15 minutes\n",
    "\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train, \n",
    "                     enable_categorical=True)\n",
    "dvalid = xgb.DMatrix(data=X_val, label=y_val, \n",
    "                     enable_categorical=True)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test, \n",
    "                    enable_categorical=True)\n",
    "dtrainvalid = xgb.DMatrix(data=X_train_valid, \n",
    "                          label=y_train_valid, \n",
    "                          enable_categorical=True)\n",
    "\n",
    "# Define the callback to stop the optimization when the trial keep being pruned. \n",
    "# The number of pruned trials is defined by the threshold.\n",
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "\n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()\n",
    "\n",
    "# Define the objective function to optimize the hyperparameters of the XGBoost model.\n",
    "def objective_GB(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse', # root mean squared error\n",
    "        'tree_method': trial.suggest_categorical('tree_method', ['approx', 'hist']), \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.2, 0.5), # Most important parameter.\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 40, log=True), # L2 regularization\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 40, log= True), # L1 regularization\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12), # Tree depth\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 200), # Min weight of each child.\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), \n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),       \n",
    "    }\n",
    "    \n",
    "    # integrated pruning for stopping unpromising trials.\n",
    "    xgb_callback = XGBoostPruningCallback(trial, f'valid-rmse')\n",
    "\n",
    "    model = XGBRegressor(random_state= 1, **params)\n",
    "    \n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=1000,\n",
    "                      evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=0,                      \n",
    "                      callbacks=[xgb_callback],\n",
    "                      )\n",
    "\n",
    "    return model.best_score\n",
    "\n",
    "# Create the study and optimize the objective function.\n",
    "# Threshold is 10.\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(200)\n",
    "study_gb = create_study(direction=\"minimize\", sampler = TPESampler(seed = 42))\n",
    "study_gb.optimize(objective_GB, timeout = train_time, n_trials= 3000, callbacks = [study_stop_cb])\n",
    "study_gb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.56263529, -11.3095334 , -10.88514568, -12.08560053,\n",
       "       -10.26554603])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = XGBRegressor(random_state=1)\n",
    "cross_val_score(base_model, X_train_valid, y_train_valid, scoring='neg_mean_absolute_error', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          11,
          30,
          31,
          35,
          39,
          41,
          43,
          48,
          52,
          56,
          72,
          74,
          81,
          95,
          113,
          118,
          134,
          140,
          161,
          165,
          166,
          167,
          170,
          172,
          176,
          178,
          182,
          183,
          184,
          185,
          193,
          194,
          195,
          198,
          199,
          200,
          201,
          211,
          215,
          217,
          223,
          229,
          238,
          243,
          250,
          254,
          261,
          293,
          359,
          426,
          441,
          445,
          448,
          449,
          459,
          460,
          464,
          465,
          466,
          467,
          474,
          482,
          487,
          500,
          501,
          504,
          507,
          509,
          519,
          520,
          524,
          527,
          528,
          539,
          547,
          556,
          566,
          570,
          584,
          633,
          677,
          685,
          697,
          704,
          811,
          879,
          896,
          899,
          921,
          965,
          973,
          976,
          984,
          986,
          995,
          996,
          1006,
          1010,
          1012,
          1013,
          1017,
          1019,
          1021,
          1024,
          1036,
          1046,
          1048,
          1049,
          1050,
          1051,
          1060,
          1062,
          1066,
          1071,
          1077,
          1082,
          1088,
          1095,
          1098,
          1101,
          1103,
          1146,
          1149,
          1153,
          1171,
          1173,
          1184,
          1202,
          1208,
          1226,
          1227,
          1230,
          1236,
          1239,
          1247,
          1270,
          1294,
          1297,
          1313,
          1329,
          1341,
          1398,
          1423,
          1441,
          1449,
          1453,
          1462,
          1490
         ],
         "y": [
          16.21871308637223,
          16.594281021165035,
          17.330078195566156,
          16.31606488874433,
          16.267877861672456,
          16.40038016117817,
          16.029759839405546,
          16.211160361309233,
          16.180785988519002,
          15.717874528494129,
          16.117811337428265,
          16.207178338315472,
          16.11468763836215,
          16.19909804057508,
          16.195333518274552,
          16.064878093859505,
          15.97284737619949,
          15.849148597668734,
          16.11207481656706,
          15.73445809405514,
          15.872109663305238,
          15.819571214163489,
          15.934402214557682,
          15.998612871522765,
          16.20231626557949,
          15.974287518520095,
          15.44846182981699,
          15.459072943188705,
          15.878811040760091,
          16.200148038446972,
          15.938411902227699,
          15.926340546115204,
          16.14649299006103,
          16.157501517261878,
          16.10161809351694,
          16.061803315477118,
          16.210679438707057,
          16.031244183717337,
          15.760204905479975,
          15.558279681782112,
          16.01271303350345,
          15.749211602511002,
          16.04041259017719,
          16.037565382014286,
          16.0407987450991,
          16.084934234821265,
          15.583582271656182,
          16.05812200380412,
          16.023273496627404,
          15.8658692869897,
          15.712341586079802,
          16.121652526685164,
          16.08720122377821,
          16.017899358334855,
          15.92351029083582,
          16.04205430372974,
          16.173018512155036,
          15.900940254212882,
          16.191576567947774,
          15.882422167810178,
          15.839842080174588,
          16.135482678152663,
          15.676696339620698,
          15.671360743029306,
          16.176879095372023,
          15.803783786643208,
          16.022840231064798,
          15.583710880953008,
          15.851536685287602,
          15.90867468936976,
          15.882200649751951,
          15.89024891227497,
          15.967058648007216,
          15.98765930178084,
          15.911352454258282,
          15.780609291649334,
          16.096077357549902,
          16.09825475736527,
          16.085403750724392,
          16.032098256683426,
          15.87743955948374,
          15.960064816634155,
          15.803173026044831,
          15.786887430532587,
          16.004616430438073,
          15.940727074239227,
          15.799719366976426,
          15.681045471056759,
          15.684369147133344,
          16.08640527586567,
          15.659100795628401,
          16.134370867065968,
          16.016105119111494,
          15.752341951068674,
          15.96346224005549,
          15.388019346311754,
          15.676014103768487,
          16.063571221688992,
          15.744170286426462,
          15.413689545243377,
          15.440364304814759,
          15.419168811760517,
          15.666444410151975,
          15.656895719235798,
          15.844466063319082,
          15.452631059156523,
          15.847557068543125,
          15.751168733879942,
          15.706030139071776,
          15.574324454568039,
          15.57656398753352,
          15.556372245045852,
          15.44116169849884,
          15.829479990995956,
          15.93906852400579,
          15.731008212640633,
          15.542305987877564,
          15.67759787809971,
          15.467032589207154,
          15.549043765599253,
          15.91823554694649,
          15.573519166044488,
          15.571261846024248,
          15.754653403762664,
          15.889100027020692,
          15.737038401797008,
          15.39818876078257,
          15.418893579343536,
          15.755531090580837,
          15.734525000015603,
          15.757472772135518,
          15.559779058462482,
          15.555014178650257,
          15.484874697665706,
          15.503582871265435,
          15.478452205797995,
          15.561367861083864,
          15.521034655077102,
          15.483552149119632,
          15.210288975491096,
          15.311511604113287,
          15.324482226227387,
          15.452527995279393,
          15.547887339242031,
          15.549173001913681,
          15.489098830281332,
          15.48337881827297,
          15.559203827639095,
          15.660702912618833,
          15.537412036745922,
          15.449718338078805,
          15.546208410177465,
          15.484549308504114,
          15.53811817172399,
          15.41342554353408
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499
         ],
         "y": [
          16.21871308637223,
          16.21871308637223,
          16.21871308637223,
          16.21871308637223,
          16.21871308637223,
          16.21871308637223,
          16.21871308637223,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          16.029759839405546,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.717874528494129,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.44846182981699,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.388019346311754,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096,
          15.210288975491096
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"eb56563e-3e76-47ed-a136-f88d3be8a7ef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eb56563e-3e76-47ed-a136-f88d3be8a7ef\")) {                    Plotly.newPlot(                        \"eb56563e-3e76-47ed-a136-f88d3be8a7ef\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,7,11,30,31,35,39,41,43,48,52,56,72,74,81,95,113,118,134,140,161,165,166,167,170,172,176,178,182,183,184,185,193,194,195,198,199,200,201,211,215,217,223,229,238,243,250,254,261,293,359,426,441,445,448,449,459,460,464,465,466,467,474,482,487,500,501,504,507,509,519,520,524,527,528,539,547,556,566,570,584,633,677,685,697,704,811,879,896,899,921,965,973,976,984,986,995,996,1006,1010,1012,1013,1017,1019,1021,1024,1036,1046,1048,1049,1050,1051,1060,1062,1066,1071,1077,1082,1088,1095,1098,1101,1103,1146,1149,1153,1171,1173,1184,1202,1208,1226,1227,1230,1236,1239,1247,1270,1294,1297,1313,1329,1341,1398,1423,1441,1449,1453,1462,1490],\"y\":[16.21871308637223,16.594281021165035,17.330078195566156,16.31606488874433,16.267877861672456,16.40038016117817,16.029759839405546,16.211160361309233,16.180785988519002,15.717874528494129,16.117811337428265,16.207178338315472,16.11468763836215,16.19909804057508,16.195333518274552,16.064878093859505,15.97284737619949,15.849148597668734,16.11207481656706,15.73445809405514,15.872109663305238,15.819571214163489,15.934402214557682,15.998612871522765,16.20231626557949,15.974287518520095,15.44846182981699,15.459072943188705,15.878811040760091,16.200148038446972,15.938411902227699,15.926340546115204,16.14649299006103,16.157501517261878,16.10161809351694,16.061803315477118,16.210679438707057,16.031244183717337,15.760204905479975,15.558279681782112,16.01271303350345,15.749211602511002,16.04041259017719,16.037565382014286,16.0407987450991,16.084934234821265,15.583582271656182,16.05812200380412,16.023273496627404,15.8658692869897,15.712341586079802,16.121652526685164,16.08720122377821,16.017899358334855,15.92351029083582,16.04205430372974,16.173018512155036,15.900940254212882,16.191576567947774,15.882422167810178,15.839842080174588,16.135482678152663,15.676696339620698,15.671360743029306,16.176879095372023,15.803783786643208,16.022840231064798,15.583710880953008,15.851536685287602,15.90867468936976,15.882200649751951,15.89024891227497,15.967058648007216,15.98765930178084,15.911352454258282,15.780609291649334,16.096077357549902,16.09825475736527,16.085403750724392,16.032098256683426,15.87743955948374,15.960064816634155,15.803173026044831,15.786887430532587,16.004616430438073,15.940727074239227,15.799719366976426,15.681045471056759,15.684369147133344,16.08640527586567,15.659100795628401,16.134370867065968,16.016105119111494,15.752341951068674,15.96346224005549,15.388019346311754,15.676014103768487,16.063571221688992,15.744170286426462,15.413689545243377,15.440364304814759,15.419168811760517,15.666444410151975,15.656895719235798,15.844466063319082,15.452631059156523,15.847557068543125,15.751168733879942,15.706030139071776,15.574324454568039,15.57656398753352,15.556372245045852,15.44116169849884,15.829479990995956,15.93906852400579,15.731008212640633,15.542305987877564,15.67759787809971,15.467032589207154,15.549043765599253,15.91823554694649,15.573519166044488,15.571261846024248,15.754653403762664,15.889100027020692,15.737038401797008,15.39818876078257,15.418893579343536,15.755531090580837,15.734525000015603,15.757472772135518,15.559779058462482,15.555014178650257,15.484874697665706,15.503582871265435,15.478452205797995,15.561367861083864,15.521034655077102,15.483552149119632,15.210288975491096,15.311511604113287,15.324482226227387,15.452527995279393,15.547887339242031,15.549173001913681,15.489098830281332,15.48337881827297,15.559203827639095,15.660702912618833,15.537412036745922,15.449718338078805,15.546208410177465,15.484549308504114,15.53811817172399,15.41342554353408],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499],\"y\":[16.21871308637223,16.21871308637223,16.21871308637223,16.21871308637223,16.21871308637223,16.21871308637223,16.21871308637223,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,16.029759839405546,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.717874528494129,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.44846182981699,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.388019346311754,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096,15.210288975491096],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eb56563e-3e76-47ed-a136-f88d3be8a7ef');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_learning_rate = 0.001\n",
    "params = study_gb.best_params\n",
    "params['learning_rate'] = low_learning_rate\n",
    "model_stage2 = xgb.train(params=params, dtrain=dtrain, \n",
    "                         num_boost_round=5000,\n",
    "                         evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                         early_stopping_rounds=50,\n",
    "                         verbose_eval=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best number of boosting rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2\n",
      "best score = 12.128686904907227\n",
      "best boosting round: 2471\n"
     ]
    }
   ],
   "source": [
    "def score_model(model: xgb.core.Booster, dmat: xgb.core.DMatrix) -> float:\n",
    "    y_true = dmat.get_label() \n",
    "    y_pred = model.predict(dmat) \n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print('Stage 2')\n",
    "print(f'best score = {score_model(model_stage2, dvalid)}')\n",
    "print(f'best boosting round: {model_stage2.best_iteration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = xgb.train(params=study_gb.best_params, dtrain=dtrainvalid, \n",
    "                        num_boost_round=model_stage2.best_iteration,\n",
    "                        verbose_eval=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model\n",
      "test score = 11.591076850891113\n",
      "Parameters\n",
      "tree_method : hist\n",
      "learning_rate : 0.001\n",
      "reg_lambda : 0.2351028496158549\n",
      "reg_alpha : 0.05879734464400952\n",
      "max_depth : 5\n",
      "min_child_weight : 1\n",
      "subsample : 0.9160465684491753\n",
      "colsample_bynode : 0.9699586846471081\n",
      "colsample_bytree : 0.6576513098358873\n",
      "colsample_bylevel : 0.8275812590568429\n",
      "max_bin : 546\n",
      "num_boost_round: 2471\n"
     ]
    }
   ],
   "source": [
    "print('Final Model')\n",
    "print(f'test score = {score_model(model_final, dtest)}')\n",
    "print('Parameters')\n",
    "for i, j in params.items():\n",
    "    print(i, ':', j)\n",
    "print(f'num_boost_round: {model_stage2.best_iteration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance: By weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cement': 4727.0,\n",
       " 'blast_furnace_slag': 2826.0,\n",
       " 'fly_ash': 1876.0,\n",
       " 'water': 3487.0,\n",
       " 'superplasticizer': 3041.0,\n",
       " 'coarse_aggregate': 4431.0,\n",
       " 'fine_aggregate': 4329.0,\n",
       " 'age': 6906.0,\n",
       " 'cement_to_water_ratio': 3985.0,\n",
       " 'fine_aggregate_to_water_ratio': 4177.0,\n",
       " 'coarse_aggregate_to_water_ratio': 3918.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model with the best parameters from the study\n",
    "model = XGBRegressor(**study_gb.best_params, enable_categorical=True)\n",
    "model = xgb.train(params=study_gb.best_params, dtrain=dtrainvalid, \n",
    "                        num_boost_round=model_stage2.best_iteration,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Plot the predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predictions vs Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(model, importance_type='weight', max_num_features=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(params = study_gb.best_params,\n",
    "        dtrain = dtest,\n",
    "        num_boost_round=model_stage2.best_iteration,\n",
    "        metrics = 'mape',\n",
    "        seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train-mape-mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train-mape-std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test-mape-mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test-mape-std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b09a374b-326b-449e-a172-7801600e16bc",
       "rows": [
        [
         "0",
         "0.5274025596386985",
         "0.03220140188965432",
         "0.6337494455676724",
         "0.10154403809109194"
        ],
        [
         "1",
         "0.42432871660316757",
         "0.026117949824927444",
         "0.5809445385881942",
         "0.0938028636945337"
        ],
        [
         "2",
         "0.35712413137206384",
         "0.03064030645092468",
         "0.5927136402575292",
         "0.07656573512455596"
        ],
        [
         "3",
         "0.3074815170080859",
         "0.025149245072590025",
         "0.5963223649181395",
         "0.08615638377154794"
        ],
        [
         "4",
         "0.28141785374508066",
         "0.020238068023248068",
         "0.5877567407791737",
         "0.08048435137920557"
        ],
        [
         "5",
         "0.26092016615700003",
         "0.025351361240570917",
         "0.5905187054290381",
         "0.08199067358475733"
        ],
        [
         "6",
         "0.2290031363151198",
         "0.027813799028833033",
         "0.5764744376125989",
         "0.06669204459185378"
        ],
        [
         "7",
         "0.1973670471017693",
         "0.028551717233638436",
         "0.5771270221088504",
         "0.06600051986545184"
        ],
        [
         "8",
         "0.17839685364532376",
         "0.028869475490991083",
         "0.5868207068165229",
         "0.08012105024272946"
        ],
        [
         "9",
         "0.15544170164479781",
         "0.02906245445682241",
         "0.580846368677888",
         "0.07680164941694723"
        ],
        [
         "10",
         "0.1410531766357809",
         "0.029390406718745363",
         "0.5736968679410633",
         "0.07854871836185569"
        ],
        [
         "11",
         "0.1279575420042796",
         "0.02683612156127587",
         "0.5755870163430886",
         "0.07990565813790428"
        ],
        [
         "12",
         "0.11439758779078509",
         "0.024233707273196643",
         "0.5736351400997978",
         "0.07855674178536054"
        ],
        [
         "13",
         "0.1035141317783032",
         "0.018543209831666733",
         "0.568492336433739",
         "0.08351091857866473"
        ],
        [
         "14",
         "0.09355985830093032",
         "0.01784178011174308",
         "0.5726237873477584",
         "0.08532307931277017"
        ],
        [
         "15",
         "0.08678388916547214",
         "0.018842503592721712",
         "0.5724609595034776",
         "0.08473689842968982"
        ],
        [
         "16",
         "0.08241848354247712",
         "0.014711011379245013",
         "0.5746180112279641",
         "0.08278089073719305"
        ],
        [
         "17",
         "0.07796605032672232",
         "0.014701581927806068",
         "0.5752229592145746",
         "0.08187826887806265"
        ],
        [
         "18",
         "0.07111888068309592",
         "0.016981851303831234",
         "0.5758144182740267",
         "0.08158362636378946"
        ],
        [
         "19",
         "0.06685377263415994",
         "0.014132827821344802",
         "0.5738879613144451",
         "0.0813244584636461"
        ],
        [
         "20",
         "0.06263099589088678",
         "0.011002305810679383",
         "0.5726649702646317",
         "0.08181606645610291"
        ],
        [
         "21",
         "0.05789467327735746",
         "0.010043169488985844",
         "0.5715214361041133",
         "0.08488899511762353"
        ],
        [
         "22",
         "0.05444482291889117",
         "0.010872083729442723",
         "0.5712142073311824",
         "0.08367307640003568"
        ],
        [
         "23",
         "0.050675023414668424",
         "0.010281308146208278",
         "0.5715832896610108",
         "0.08288666561569817"
        ],
        [
         "24",
         "0.046831423808437404",
         "0.008677934317295752",
         "0.5699649572355606",
         "0.0812140235816081"
        ],
        [
         "25",
         "0.04363185661531677",
         "0.007549222393368959",
         "0.57032841421574",
         "0.0812903684810915"
        ],
        [
         "26",
         "0.04208222235376752",
         "0.008365830280352449",
         "0.5688897595772647",
         "0.07920897675376533"
        ],
        [
         "27",
         "0.03981096324744989",
         "0.00759756927950385",
         "0.5694794067007257",
         "0.0789590922127402"
        ],
        [
         "28",
         "0.036446963409183894",
         "0.006755651698162685",
         "0.5681271243316353",
         "0.07928781322232684"
        ],
        [
         "29",
         "0.03535891369623473",
         "0.007283411656520454",
         "0.5678859788323211",
         "0.07943430179169406"
        ],
        [
         "30",
         "0.034093554725889895",
         "0.007211186835049595",
         "0.5701902154899994",
         "0.08294128879594809"
        ],
        [
         "31",
         "0.03222811341512429",
         "0.008089095556442688",
         "0.5713204920065615",
         "0.08361496484636502"
        ],
        [
         "32",
         "0.030105176284155006",
         "0.007557859679777452",
         "0.5724889399452476",
         "0.0826100951367784"
        ],
        [
         "33",
         "0.02751591083350755",
         "0.0074608695040792655",
         "0.5731499841379238",
         "0.08256394962238596"
        ],
        [
         "34",
         "0.02588890205065052",
         "0.00787023638014455",
         "0.5727537020846424",
         "0.08229319730478944"
        ],
        [
         "35",
         "0.024415828011686708",
         "0.007438493971941598",
         "0.5728730549175577",
         "0.08263248800613207"
        ],
        [
         "36",
         "0.02196911191797234",
         "0.005894873460839832",
         "0.5728846301923574",
         "0.08207603478282094"
        ],
        [
         "37",
         "0.020561700189119732",
         "0.00533000264436148",
         "0.5730745476033786",
         "0.0819333116038568"
        ],
        [
         "38",
         "0.019593581509578354",
         "0.005418894788209336",
         "0.5736665397049788",
         "0.08194210792933557"
        ],
        [
         "39",
         "0.018998565025820237",
         "0.005393665765852245",
         "0.5738263986799043",
         "0.08153193288758448"
        ],
        [
         "40",
         "0.01724249986880268",
         "0.004175886119206575",
         "0.5732820350364114",
         "0.0810878062642352"
        ],
        [
         "41",
         "0.016174574028060947",
         "0.0040347304293225405",
         "0.573355034607356",
         "0.0803492491544031"
        ],
        [
         "42",
         "0.015363281134239107",
         "0.0038968939831608147",
         "0.5735249009197153",
         "0.08020568971444172"
        ],
        [
         "43",
         "0.014471330989578516",
         "0.0038885967439867895",
         "0.5736222812526858",
         "0.08034628648825651"
        ],
        [
         "44",
         "0.013632450620894835",
         "0.004085365748383516",
         "0.5730217774773965",
         "0.07913400623586393"
        ],
        [
         "45",
         "0.013030309357321648",
         "0.003953649870787265",
         "0.5731589069256154",
         "0.07937005398811955"
        ],
        [
         "46",
         "0.012344934721173801",
         "0.0036958890752935942",
         "0.5727878822622462",
         "0.07949656812203991"
        ],
        [
         "47",
         "0.011823332095308975",
         "0.003666191430268463",
         "0.5729791832317311",
         "0.07963617789565738"
        ],
        [
         "48",
         "0.01072669571829056",
         "0.00306907630669974",
         "0.5722694024621288",
         "0.08006545257907177"
        ],
        [
         "49",
         "0.010484668382740708",
         "0.003158561167852133",
         "0.57225470230017",
         "0.08011854394587523"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2471
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mape-mean</th>\n",
       "      <th>train-mape-std</th>\n",
       "      <th>test-mape-mean</th>\n",
       "      <th>test-mape-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.527403</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>0.633749</td>\n",
       "      <td>0.101544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424329</td>\n",
       "      <td>0.026118</td>\n",
       "      <td>0.580945</td>\n",
       "      <td>0.093803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357124</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>0.592714</td>\n",
       "      <td>0.076566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307482</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.596322</td>\n",
       "      <td>0.086156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.281418</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>0.587757</td>\n",
       "      <td>0.080484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.570633</td>\n",
       "      <td>0.080056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.080055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.080055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.080055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.080055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2471 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train-mape-mean  train-mape-std  test-mape-mean  test-mape-std\n",
       "0            0.527403        0.032201        0.633749       0.101544\n",
       "1            0.424329        0.026118        0.580945       0.093803\n",
       "2            0.357124        0.030640        0.592714       0.076566\n",
       "3            0.307482        0.025149        0.596322       0.086156\n",
       "4            0.281418        0.020238        0.587757       0.080484\n",
       "...               ...             ...             ...            ...\n",
       "2466         0.000157        0.000001        0.570633       0.080056\n",
       "2467         0.000157        0.000002        0.570632       0.080055\n",
       "2468         0.000157        0.000002        0.570632       0.080055\n",
       "2469         0.000157        0.000002        0.570632       0.080055\n",
       "2470         0.000157        0.000002        0.570632       0.080055\n",
       "\n",
       "[2471 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['train-mape-mean'], label='Training MAPE', color='blue')\n",
    "plt.plot(cv_results['test-mape-mean'], label='Validation MAPE', color='orange')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training vs Validation RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
